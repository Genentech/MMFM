{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add autoreload magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scanpy as sc\n",
    "from addict import Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mmfm.data import dgp_iccite_data\n",
    "from mmfm.utils_eval import (\n",
    "    load_all_fm_models,\n",
    "    process_all_fm_models,\n",
    "    get_model_battery_of_best_models,\n",
    "    predict_on_testset_mmfm,\n",
    "    predict_on_testset_fsi,\n",
    ")\n",
    "from mmfm.models import VectorFieldModel, MultiVectorFieldModelTCFM\n",
    "\n",
    "\n",
    "# plt.style.use([\"science\", \"no-latex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROD = True\n",
    "DGP = \"a\"\n",
    "coupling = \"cot\"\n",
    "minimum_seeds = 1\n",
    "batch_size = None\n",
    "hvg = None\n",
    "train_test_split = 0.8\n",
    "subsample_frac = None\n",
    "top_n_effects = None\n",
    "leave_out_middle = None\n",
    "leave_out_end = None\n",
    "preset = \"z\"\n",
    "n_samples_per_c_in_b = 100\n",
    "use_pca = 10\n",
    "embedding_type = \"free\"\n",
    "classifier_free = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "path_name_fsi = \"/home/rohbeckm/scratch/results/dgp_iccite/results_fsi\"\n",
    "verbose = False\n",
    "\n",
    "if preset == \"a\":\n",
    "    n_classes = 50\n",
    "    label_list = list(range(1, 50 + 1))\n",
    "    df_experiment = pd.read_csv(\n",
    "        \"/home/rohbeckm/code/mmfm/benchmark/dgp_iccite/data/experiment_50_20_random.csv\", index_col=0\n",
    "    )\n",
    "elif preset == \"b\":\n",
    "    n_classes = 70\n",
    "    label_list = list(range(1, 70 + 1))\n",
    "    df_experiment = pd.read_csv(\n",
    "        \"/home/rohbeckm/code/mmfm/benchmark/dgp_iccite/data/experiment_70_30_random.csv\", index_col=0\n",
    "    )\n",
    "elif preset == \"c\":\n",
    "    n_classes = 90\n",
    "    label_list = list(range(1, 90 + 1))\n",
    "    df_experiment = pd.read_csv(\n",
    "        \"/home/rohbeckm/code/mmfm/benchmark/dgp_iccite/data/experiment_90_40_random.csv\", index_col=0\n",
    "    )\n",
    "elif preset == \"z\":\n",
    "    n_classes = 60\n",
    "    label_list = list(range(1, 60 + 1))\n",
    "    df_experiment = pd.read_csv(\n",
    "        \"/home/rohbeckm/code/mmfm/benchmark/dgp_iccite/data/experiment_4t_60_30_random.csv\", index_col=0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_files(DGP, PROD, load_from_parquet=True, filter_values=None):\n",
    "    if load_from_parquet & (Path(\"data\") / f\"df_gt_{DGP}.parquet\").exists():\n",
    "        df = pd.read_parquet(Path(\"data\") / f\"df_gt_{DGP}.parquet\")\n",
    "        # Try to convert each value in column flow_variance to float if possible, otherwise leave value as string\n",
    "        try:\n",
    "            df[\"flow_variance\"] = df[\"flow_variance\"].astype(float)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        with open(Path(\"data\") / f\"grouping_columns_{DGP}.pkl\", \"rb\") as f:\n",
    "            grouping_columns = pickle.load(f)\n",
    "        with open(Path(\"data\") / f\"performance_columns_{DGP}.pkl\", \"rb\") as f:\n",
    "            performance_columns = pickle.load(f)\n",
    "    else:\n",
    "        df, grouping_columns, performance_columns = load_all_fm_models(\n",
    "            path=\"/home/rohbeckm/scratch/results/dgp_iccite/results_mmfm\", production=PROD, dgp=DGP, filter_values=filter_values\n",
    "        )\n",
    "\n",
    "        # Save everything\n",
    "        # Convert\n",
    "        df[\"flow_variance\"] = df[\"flow_variance\"].astype(str)\n",
    "        df.to_parquet(Path(\"data\") / f\"df_gt_{DGP}.parquet\")\n",
    "        # Try to convert each value in column flow_variance to float if possible, otherwise leave value as string\n",
    "        try:\n",
    "            df[\"flow_variance\"] = df[\"flow_variance\"].astype(float)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        with open(Path(\"data\") / f\"grouping_columns_{DGP}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(grouping_columns, f)\n",
    "        with open(Path(\"data\") / f\"performance_columns_{DGP}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(performance_columns, f)\n",
    "\n",
    "    return df, grouping_columns, performance_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_battery_of_best_models(\n",
    "    df,\n",
    "    dgp,\n",
    "    grouping_columns,\n",
    "    select_by=\"mmd_mean\",\n",
    "    device=\"cuda\",\n",
    "    n_top_models=1,\n",
    "    n_top_seeds=5,\n",
    "    model_string=\"dgp_waves\",\n",
    "    label_list=None,\n",
    "    verbose=True,\n",
    "    average_out_seed=True,\n",
    "    model_type=\"mmfm\",\n",
    "):\n",
    "    \"\"\"Select the best MMFM model and return it with all its seeds.\"\"\"\n",
    "\n",
    "    # If eval_points is given, filter df by this\n",
    "    # Note, df only contains the valid data. We pick the best model averaged over all seeds\n",
    "    def weighted_avg(group_df, whole_df, values, weights):\n",
    "        v = whole_df.loc[group_df.index, values]\n",
    "        w = whole_df.loc[group_df.index, weights]\n",
    "        return (v * w).sum() / w.sum()\n",
    "\n",
    "    def weighted_max(group_df, whole_df, values, weights):\n",
    "        v = whole_df.loc[group_df.index, values]\n",
    "        w = whole_df.loc[group_df.index, weights]\n",
    "        return (v * w).max()\n",
    "\n",
    "    if average_out_seed:\n",
    "        grouping = [x for x in grouping_columns if x not in [\"marginal\", \"c\", \"time\", \"seed\"]]\n",
    "    else:\n",
    "        grouping = [x for x in grouping_columns if x not in [\"marginal\", \"c\", \"time\"]]\n",
    "\n",
    "    df_agg = (\n",
    "        df.drop(columns=[\"marginal\", \"c\", \"time\"])\n",
    "        .groupby(grouping)\n",
    "        .agg(\n",
    "            mmd_mean=(\"mmd\", lambda x: weighted_avg(x, df, \"mmd\", \"weight\")),\n",
    "            mmd_max=(\"mmd\", lambda x: weighted_max(x, df, \"mmd\", \"weight\")),\n",
    "            mmd_std=(\"mmd\", \"std\"),\n",
    "            mmd_median_mean=(\"mmd_median\", lambda x: weighted_avg(x, df, \"mmd_median\", \"weight\")),\n",
    "            mmd_median_max=(\"mmd_median\", lambda x: weighted_max(x, df, \"mmd_median\", \"weight\")),\n",
    "            mmd_median_std=(\"mmd_median\", \"std\"),\n",
    "            wasserstein_mean=(\"wasserstein\", lambda x: weighted_avg(x, df, \"wasserstein\", \"weight\")),\n",
    "            wasserstein_max=(\"wasserstein\", lambda x: weighted_max(x, df, \"wasserstein\", \"weight\")),\n",
    "            wasserstein_std=(\"wasserstein\", \"std\"),\n",
    "            mean_diff_l1_mean=(\"mean_diff_l1\", lambda x: weighted_avg(x, df, \"mean_diff_l1\", \"weight\")),\n",
    "            mean_diff_l1_max=(\"mean_diff_l1\", lambda x: weighted_max(x, df, \"mean_diff_l1\", \"weight\")),\n",
    "            mean_diff_l1_std=(\"mean_diff_l1\", \"std\"),\n",
    "            mean_diff_l2_mean=(\"mean_diff_l2\", lambda x: weighted_avg(x, df, \"mean_diff_l2\", \"weight\")),\n",
    "            mean_diff_l2_max=(\"mean_diff_l2\", lambda x: weighted_max(x, df, \"mean_diff_l2\", \"weight\")),\n",
    "            mean_diff_l2_std=(\"mean_diff_l2\", \"std\"),\n",
    "            # kl_div_mean=(\"kl_div\", lambda x: weighted_avg(x, df, \"kl_div\", \"weight\")),\n",
    "            # kl_div_max=(\"kl_div\", lambda x: weighted_max(x, df, \"kl_div\", \"weight\")),\n",
    "            # kl_div_std=(\"kl_div\", \"std\"),\n",
    "            filename_first=(\"filename\", \"first\"),\n",
    "        )\n",
    "    ).reset_index()\n",
    "\n",
    "    # Find best model according to MMD/Wasserstein mean and std on valid data\n",
    "    # and compute scores on test data for the best model\n",
    "    model_battery = Dict()\n",
    "    model_guidances = Dict()\n",
    "    model_states = Dict()\n",
    "    for n in range(1, n_top_models + 1):\n",
    "        # for c in df[\"c\"].unique():\n",
    "        # print(f\"Optimizing for condition c: {c}\")\n",
    "        df_top_valid = df_agg.sort_values(by=select_by, ascending=True).head(1).reset_index(drop=True)\n",
    "        if verbose:\n",
    "            print(f\"Best model: {df_top_valid['filename_first'].values[n-1]}\")\n",
    "        model_guidances[n - 1] = df_top_valid[\"guidance\"].values[n - 1]\n",
    "\n",
    "        # Load the model from its filename and all its seed-variations\n",
    "        model_path = df_top_valid[\"filename_first\"].values[n - 1]\n",
    "        model_path = model_path.replace(\"df_results.csv\", \"model.pt\")\n",
    "\n",
    "        for seed in range(n_top_seeds):\n",
    "            # Replace \"dgp2_{seed}\" with \"dgp2_x\" in the path\n",
    "            current_seed = model_path.split(\"_\")[5]\n",
    "            model_path = model_path.replace(f\"{model_string}_{dgp}_{current_seed}\", f\"{model_string}_{dgp}_{seed}\")\n",
    "            filename = model_path.split(\"/\")[-2]\n",
    "            try:\n",
    "                state = torch.load(model_path, weights_only=True)\n",
    "                if verbose:\n",
    "                    print(f\"✓ {filename}\")\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                if verbose:\n",
    "                    print(f\"✗ {filename}\")\n",
    "                continue\n",
    "\n",
    "            if model_type == \"mmfm\":\n",
    "                mmfm_model = VectorFieldModel(\n",
    "                    data_dim=state[\"dimension\"] if \"dimension\" in state else state[\"use_pca\"],\n",
    "                    x_latent_dim=state[\"x_latent_dim\"],\n",
    "                    time_embed_dim=state[\"time_embed_dim\"],\n",
    "                    cond_embed_dim=state[\"cond_embed_dim\"],\n",
    "                    conditional_model=state[\"conditional_model\"],\n",
    "                    embedding_type=state[\"embedding_type\"],\n",
    "                    n_classes=state[\"n_classes\"],\n",
    "                    label_list=label_list,\n",
    "                    normalization=state[\"normalization\"],\n",
    "                    activation=state[\"activation\"],\n",
    "                    affine_transform=state[\"affine_transform\"],\n",
    "                    sum_time_embed=state[\"sum_time_embed\"],\n",
    "                    sum_cond_embed=state[\"sum_cond_embed\"],\n",
    "                    max_norm_embedding=state[\"max_norm_embedding\"],\n",
    "                    num_out_layers=state[\"num_out_layers\"],\n",
    "                    spectral_norm=state[\"spectral_norm\"],\n",
    "                    dropout=state[\"dropout\"],\n",
    "                    conditional_bias=state[\"conditional_bias\"],\n",
    "                    keep_constants=state[\"keep_constants\"],\n",
    "                ).to(device)\n",
    "            elif model_type == \"totcfm\":\n",
    "                mmfm_model = MultiVectorFieldModelTCFM(\n",
    "                    model_list=[0, 0.33, 0.67, 1.0],\n",
    "                    data_dim=state[\"dimension\"] if \"dimension\" in state else state[\"use_pca\"],\n",
    "                    x_latent_dim=state[\"x_latent_dim\"],\n",
    "                    time_embed_dim=state[\"time_embed_dim\"],\n",
    "                    cond_embed_dim=state[\"cond_embed_dim\"],\n",
    "                    conditional_model=state[\"conditional_model\"],\n",
    "                    embedding_type=state[\"embedding_type\"],\n",
    "                    n_classes=state[\"n_classes\"],\n",
    "                    label_list=label_list,\n",
    "                    normalization=state[\"normalization\"],\n",
    "                    activation=state[\"activation\"],\n",
    "                    affine_transform=state[\"affine_transform\"],\n",
    "                    sum_time_embed=state[\"sum_time_embed\"],\n",
    "                    sum_cond_embed=state[\"sum_cond_embed\"],\n",
    "                    max_norm_embedding=state[\"max_norm_embedding\"],\n",
    "                    num_out_layers=state[\"num_out_layers\"],\n",
    "                    spectral_norm=state[\"spectral_norm\"],\n",
    "                    dropout=state[\"dropout\"],\n",
    "                    conditional_bias=state[\"conditional_bias\"],\n",
    "                    keep_constants=state[\"keep_constants\"],\n",
    "                ).to(device)\n",
    "\n",
    "            mmfm_model.load_state_dict(state[\"state_dict\"], strict=True)\n",
    "            model_battery[n - 1][seed] = mmfm_model\n",
    "            model_states[n - 1][seed] = state\n",
    "\n",
    "            # Print average values of absolute model weights in state[\"state_dict\"]\n",
    "            # print(\n",
    "            #     f\"Average absolute model weights: {np.mean([torch.mean(torch.abs(p)).item() for p in mmfm_model.parameters()])}\"\n",
    "            # )\n",
    "\n",
    "    return df_top_valid, model_battery, model_states, model_guidances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\"/home/rohbeckm/code/mmfm/data/icCITE-plex_filtered_top_drugs.h5ad\")\n",
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "if preset in [\"z\", \"y\"]:\n",
    "    # Convert age to float timepoints\n",
    "    adata.obs[\"timepoint\"] = adata.obs[\"timepoint\"].astype(str).str.extract(r\"(\\d+)\").astype(int)\n",
    "    # Create new timepoint 0 for all non-stimulated data\n",
    "    adata.obs.loc[adata.obs[\"treatment\"].isin([\"No stim_1uM\", \"No stim_100nM\", \"No stim_10uM\"]), \"timepoint\"] = 0\n",
    "    adata.obs[\"timepoint\"] = adata.obs[\"timepoint\"] / 72\n",
    "\n",
    "    # Round to two digits\n",
    "    adata.obs[\"timepoint\"] = adata.obs[\"timepoint\"].round(2)\n",
    "    adata.obs[\"Timepoint\"] = adata.obs[\"Timepoint\"].astype(str)\n",
    "    adata.obs.loc[(adata.obs.timepoint == 0.0), \"Timepoint\"] = \"0h\"\n",
    "\n",
    "# Gene activateion\n",
    "activation_gene = [\n",
    "    \"TNFRSF18\",\n",
    "    \"TNFRSF4\",\n",
    "    \"IL12RB2\",\n",
    "    \"LMNA\",\n",
    "    \"RRM2\",\n",
    "    \"DUSP2\",\n",
    "    \"GBE1\",\n",
    "    \"ZBED2\",\n",
    "    \"IER3\",\n",
    "    \"LTA\",\n",
    "    \"CD109\",\n",
    "    \"TNFAIP3\",\n",
    "    \"SYTL3\",\n",
    "    \"GARS\",\n",
    "    \"SNHG15\",\n",
    "    \"NAMPT\",\n",
    "    \"HILPDA\",\n",
    "    \"DUSP4\",\n",
    "    \"RNF19A\",\n",
    "    \"NINJ1\",\n",
    "    \"IL2RA\",\n",
    "    \"DDIT4\",\n",
    "    \"PGAM1\",\n",
    "    \"MICAL2\",\n",
    "    \"SLC43A3\",\n",
    "    \"SLC3A2\",\n",
    "    \"LAG3\",\n",
    "    \"LINC02341\",\n",
    "    \"GNA15\",\n",
    "    \"ZBTB32\",\n",
    "    \"MIR155HG\",\n",
    "    \"PIM3\",\n",
    "    \"GK\",\n",
    "]\n",
    "\n",
    "sc.tl.score_genes(adata, activation_gene, score_name=\"score_activation_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0  # Holdout ist constant across seeds\n",
    "if preset in [\"z\", \"y\"]:\n",
    "    filename_full_data = f\"/home/rohbeckm/code/mmfm/benchmark/dgp_iccite/data/iccite_4t_{hvg}_{use_pca}_{subsample_frac}_{coupling}_{batch_size}_{n_samples_per_c_in_b}_{train_test_split}_{None}_{None}_{None}_{seed}_{preset}.pt\"\n",
    "else:\n",
    "    filename_full_data = f\"/home/rohbeckm/code/mmfm/benchmark/dgp_iccite/data/iccite_{hvg}_{use_pca}_{subsample_frac}_{coupling}_{batch_size}_{n_samples_per_c_in_b}_{train_test_split}_{None}_{None}_{None}_{seed}_{preset}.pt\"\n",
    "\n",
    "data = torch.load(filename_full_data)\n",
    "\n",
    "names_holdout = df_experiment.loc[df_experiment[\"leave_out\"].isin([\"beg\", \"mid\", \"end\"]), \"treatment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "process_fm_models_partial = partial(\n",
    "    process_all_fm_models,\n",
    "    plot=False,\n",
    "    verbose=False,\n",
    "    minimum_seeds=minimum_seeds,\n",
    "    data_cols=[\n",
    "        \"coupling\",\n",
    "        \"dgp\",\n",
    "        \"interpolation\",\n",
    "        \"guidance\",\n",
    "        \"embedding_type\",\n",
    "        \"classifier_free\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COT-MMFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, grouping_columns, performance_columns = load_all_files(DGP, PROD, load_from_parquet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[\n",
    "    (df[\"preset\"] == preset)\n",
    "    & (df[\"coupling\"] == coupling)\n",
    "    & (df[\"train_test_split\"] == train_test_split)\n",
    "    & (df[\"n_samples_per_c_in_b\"] == n_samples_per_c_in_b)\n",
    "    & (df[\"use_pca\"] == use_pca)\n",
    "    & (df[\"preset\"] == preset)\n",
    "    & (df[\"model_type\"] == \"mmfm\")\n",
    "]\n",
    "if not classifier_free:\n",
    "    df = df.loc[~df[\"classifier_free\"]]\n",
    "\n",
    "# Filter for validation results\n",
    "df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "df = df.loc[~df[\"train\"]]\n",
    "\n",
    "df, grouping_columns, performance_columns = process_fm_models_partial(df, grouping_columns, performance_columns)\n",
    "\n",
    "# We only compare to natural cubic splines on FSI later, so let's focus on\n",
    "# these interpolations for MMFM as well\n",
    "df_cubic = df.loc[(df[\"interpolation\"] == \"cubic\")]\n",
    "\n",
    "print(df_cubic.shape)\n",
    "\n",
    "# Add weight column to lay focus on conditional generalization\n",
    "df_cubic[\"weight\"] = 1\n",
    "\n",
    "# this is our extra validation timepoint\n",
    "# Note, that for a fair comparison we provide this sample as training data to FSI\n",
    "add_time_cond = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering for target validation time and c\n",
    "# Use condition 25 for validation\n",
    "for valid_filter in [11]:  # [i for i, k in data[\"ps\"].items() if k in names_holdout]:\n",
    "    print(f\"Validating for condition {valid_filter}\")\n",
    "    df_cubic_valid = df_cubic.loc[(df_cubic[\"c\"] == valid_filter)]\n",
    "\n",
    "    for select_by in [\n",
    "        # \"mean_diff_l1_mean\",\n",
    "        # \"mean_diff_l2_mean\",\n",
    "        # \"mmd_mean\",\n",
    "        # \"mmd_median_mean\",\n",
    "        \"wasserstein_mean\",\n",
    "    ]:\n",
    "        print(f\"Selecting by {select_by}\")\n",
    "        _, model_battery, model_states, model_guidances = get_model_battery_of_best_models(\n",
    "            df_cubic_valid,\n",
    "            DGP,\n",
    "            grouping_columns,\n",
    "            select_by=select_by,\n",
    "            device=\"cuda\",\n",
    "            n_top_models=1,\n",
    "            n_top_seeds=5,\n",
    "            model_string=\"dgp_iccite\",\n",
    "            label_list=label_list,\n",
    "        )\n",
    "\n",
    "        X_test, y_test, t_test, n_classes, timepoints, all_classes, ps = dgp_iccite_data(\n",
    "            hvg,\n",
    "            subsample_frac,\n",
    "            use_pca,\n",
    "            coupling,\n",
    "            batch_size,\n",
    "            n_samples_per_c_in_b,\n",
    "            train_test_split,\n",
    "            DGP,\n",
    "            top_n_effects,\n",
    "            leave_out_middle,\n",
    "            leave_out_end,\n",
    "            preset=preset,\n",
    "            return_data=\"test\",\n",
    "            seed=0,\n",
    "        )\n",
    "\n",
    "        df_cubic_results_mmfm, trajectories_test = predict_on_testset_mmfm(\n",
    "            model_battery=model_battery,\n",
    "            model_states=model_states,\n",
    "            model_guidances=model_guidances,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            t_test=t_test,\n",
    "            device=device,\n",
    "            steps=101,\n",
    "            method=\"rk4\",\n",
    "        )\n",
    "        df_cubic_results_mmfm[\"model\"] = \"COT-MMFM\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OT-CFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, grouping_columns, performance_columns = load_all_files(DGP, PROD, load_from_parquet=True)\n",
    "\n",
    "df = df.loc[\n",
    "    (df[\"preset\"] == preset)\n",
    "    & (df[\"coupling\"] == coupling)\n",
    "    & (df[\"train_test_split\"] == train_test_split)\n",
    "    & (df[\"n_samples_per_c_in_b\"] == n_samples_per_c_in_b)\n",
    "    & (df[\"use_pca\"] == use_pca)\n",
    "    & (df[\"preset\"] == preset)\n",
    "    & (df[\"model_type\"] == \"fm\")\n",
    "]\n",
    "if not classifier_free:\n",
    "    df = df.loc[~df[\"classifier_free\"]]\n",
    "\n",
    "# Filter for validation results\n",
    "df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "df = df.loc[~df[\"train\"]]\n",
    "\n",
    "df, grouping_columns, performance_columns = process_fm_models_partial(df, grouping_columns, performance_columns)\n",
    "\n",
    "df_cubic = df.loc[(df[\"interpolation\"] == \"cubic\")]\n",
    "df_cubic[\"weight\"] = 1\n",
    "df_cubic_valid = df_cubic.loc[(df_cubic[\"c\"] == valid_filter)]\n",
    "\n",
    "print(df_cubic.shape)\n",
    "\n",
    "_, model_battery, model_states, model_guidances = get_model_battery_of_best_models(\n",
    "    df_cubic_valid,\n",
    "    DGP,\n",
    "    grouping_columns,\n",
    "    select_by=select_by,\n",
    "    device=\"cuda\",\n",
    "    n_top_models=1,\n",
    "    n_top_seeds=5,\n",
    "    model_string=\"dgp_iccite\",\n",
    "    label_list=label_list,\n",
    ")\n",
    "\n",
    "df_cubic_results_fm, trajectories_test = predict_on_testset_mmfm(\n",
    "    model_battery=model_battery,\n",
    "    model_states=model_states,\n",
    "    model_guidances=model_guidances,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    t_test=t_test,\n",
    "    device=device,\n",
    "    steps=101,\n",
    "    method=\"rk4\",\n",
    ")\n",
    "df_cubic_results_fm[\"model\"] = \"OT-CFM\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L-COT-MMFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, grouping_columns, performance_columns = load_all_files(DGP, PROD, load_from_parquet=True)\n",
    "\n",
    "df = df.loc[\n",
    "    (df[\"preset\"] == preset)\n",
    "    & (df[\"coupling\"] == coupling)\n",
    "    & (df[\"train_test_split\"] == train_test_split)\n",
    "    & (df[\"n_samples_per_c_in_b\"] == n_samples_per_c_in_b)\n",
    "    & (df[\"use_pca\"] == use_pca)\n",
    "    & (df[\"preset\"] == preset)\n",
    "    & (df[\"model_type\"] == \"mmfm\")\n",
    "]\n",
    "if not classifier_free:\n",
    "    df = df.loc[~df[\"classifier_free\"]]\n",
    "\n",
    "# Filter for validation results\n",
    "df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "df = df.loc[~df[\"train\"]]\n",
    "\n",
    "df, grouping_columns, performance_columns = process_fm_models_partial(df, grouping_columns, performance_columns)\n",
    "\n",
    "df_cubic = df.loc[(df[\"interpolation\"] == \"linear\")]\n",
    "df_cubic[\"weight\"] = 1\n",
    "df_cubic_valid = df_cubic.loc[(df_cubic[\"c\"] == valid_filter)]\n",
    "\n",
    "_, model_battery, model_states, model_guidances = get_model_battery_of_best_models(\n",
    "    df_cubic_valid,\n",
    "    DGP,\n",
    "    grouping_columns,\n",
    "    select_by=select_by,\n",
    "    device=\"cuda\",\n",
    "    n_top_models=1,\n",
    "    n_top_seeds=5,\n",
    "    model_string=\"dgp_iccite\",\n",
    "    label_list=label_list,\n",
    ")\n",
    "\n",
    "df_cubic_results_pcfm, trajectories_test = predict_on_testset_mmfm(\n",
    "    model_battery=model_battery,\n",
    "    model_states=model_states,\n",
    "    model_guidances=model_guidances,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    t_test=t_test,\n",
    "    device=device,\n",
    "    steps=101,\n",
    "    method=\"rk4\",\n",
    ")\n",
    "df_cubic_results_pcfm[\"model\"] = \"L-COT-MMFM\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-OT-CFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, grouping_columns, performance_columns = load_all_files(DGP, PROD, load_from_parquet=True, filter_values=\"totcfm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[\n",
    "    (df[\"preset\"] == preset)\n",
    "    & (df[\"coupling\"] == coupling)\n",
    "    & (df[\"train_test_split\"] == train_test_split)\n",
    "    & (df[\"n_samples_per_c_in_b\"] == n_samples_per_c_in_b)\n",
    "    & (df[\"use_pca\"] == use_pca)\n",
    "    & (df[\"preset\"] == preset)\n",
    "    & (df[\"model_type\"] == \"totcfm\")\n",
    "]\n",
    "if not classifier_free:\n",
    "    df = df.loc[~df[\"classifier_free\"]]\n",
    "\n",
    "# Filter for validation results\n",
    "df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "df = df.loc[~df[\"train\"]]\n",
    "\n",
    "df, grouping_columns, performance_columns = process_fm_models_partial(df, grouping_columns, performance_columns)\n",
    "\n",
    "df_cubic = df.loc[(df[\"interpolation\"] == \"linear\")]\n",
    "df_cubic[\"weight\"] = 1\n",
    "df_cubic_valid = df_cubic.loc[(df_cubic[\"c\"] == valid_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cubic_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model_battery, model_states, model_guidances = get_model_battery_of_best_models(\n",
    "    df_cubic_valid,\n",
    "    DGP,\n",
    "    grouping_columns,\n",
    "    select_by=select_by,\n",
    "    device=\"cuda\",\n",
    "    n_top_models=1,\n",
    "    n_top_seeds=5,\n",
    "    model_string=\"dgp_iccite\",\n",
    "    label_list=label_list,\n",
    "    model_type=\"totcfm\",\n",
    ")\n",
    "\n",
    "df_cubic_results_totcfm, trajectories_test = predict_on_testset_mmfm(\n",
    "    model_battery=model_battery,\n",
    "    model_states=model_states,\n",
    "    model_guidances=model_guidances,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    t_test=t_test,\n",
    "    device=device,\n",
    "    steps=101,\n",
    "    method=\"rk4\",\n",
    ")\n",
    "df_cubic_results_totcfm[\"model\"] = \"T-OT-CFM\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate FSI models on the same test data\n",
    "df_cubic_results_fsi = []\n",
    "for seed in range(3):\n",
    "    filename = (\n",
    "        f\"dgp_iccite_{DGP}_{seed}_{hvg}_{subsample_frac}_{use_pca}_{batch_size}_{n_samples_per_c_in_b}\"\n",
    "        + f\"_{train_test_split}_{top_n_effects}_{leave_out_middle}_{leave_out_end}_{preset}\"\n",
    "    )\n",
    "    results_path = Path(path_name_fsi) / filename\n",
    "\n",
    "    df_results_fsi = predict_on_testset_fsi(\n",
    "        results_path,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        t_test,\n",
    "        seed=seed,\n",
    "        coupling=coupling,\n",
    "        n_classes=len(label_list),\n",
    "        plot_results=False,\n",
    "        ncols=5,\n",
    "    )\n",
    "    df_cubic_results_fsi.append(df_results_fsi)\n",
    "\n",
    "df_cubic_results_fsi = pd.concat(df_cubic_results_fsi).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use([\"science\", \"no-latex\"])\n",
    "from mmfm.utils import COLORMAP10, ThickerLine2D\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"axes.labelsize\": 18,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"xtick.labelsize\": 18,\n",
    "    \"ytick.labelsize\": 18,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"legend.title_fontsize\": 22,\n",
    "    \"figure.titlesize\": 30,\n",
    "}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "df_results = pd.concat(\n",
    "    [df_cubic_results_mmfm, df_cubic_results_fsi, df_cubic_results_fm, df_cubic_results_pcfm, df_cubic_results_totcfm], ignore_index=True, axis=0\n",
    ").reset_index(drop=True)\n",
    "\n",
    "leave_out_beg_idx = [\n",
    "    k for k, v in ps.items() if v in df_experiment.loc[(df_experiment[\"leave_out\"] == \"beg\"), \"treatment\"].values\n",
    "]\n",
    "leave_out_mid_idx = [\n",
    "    k for k, v in ps.items() if v in df_experiment.loc[(df_experiment[\"leave_out\"] == \"mid\"), \"treatment\"].values\n",
    "]\n",
    "leave_out_end_idx = [\n",
    "    k for k, v in ps.items() if v in df_experiment.loc[(df_experiment[\"leave_out\"] == \"end\"), \"treatment\"].values\n",
    "]\n",
    "\n",
    "df_results.loc[:, \"training\"] = True\n",
    "df_results.loc[(df_results[\"c\"].isin(leave_out_beg_idx)) & (df_results[\"time\"] == 0.33), \"training\"] = False\n",
    "df_results.loc[(df_results[\"c\"].isin(leave_out_mid_idx)) & (df_results[\"time\"] == 0.67), \"training\"] = False\n",
    "df_results.loc[(df_results[\"c\"].isin(leave_out_end_idx)) & (df_results[\"time\"] == 1.00), \"training\"] = False\n",
    "\n",
    "df_experiment[\"group\"] = pd.cut(\n",
    "    df_experiment[\"strength\"],\n",
    "    bins=[-np.inf, 1.75, 2.4, 2.9, np.inf],\n",
    "    labels=[\"weak\", \"small\", \"medium\", \"strong\"],\n",
    ")\n",
    "\n",
    "# Group strength into 3 categories\n",
    "df_results[\"treatment\"] = df_results[\"c\"].map(ps)\n",
    "# Joing group column from df_experiment using the treatment column as key\n",
    "df_results = df_results.merge(df_experiment[[\"treatment\", \"group\"]], on=\"treatment\", how=\"left\")\n",
    "\n",
    "df_results.loc[\n",
    "    (df_results[\"c\"].isin(leave_out_end_idx)) & (df_results[\"time\"] == 1.00) & (df_results[\"model\"] == \"FM\"),\n",
    "    [\"mean_diff_l1\", \"mean_diff_l2\", \"kl_div\", \"mmd\", \"mmd_median\", \"wasserstein\"],\n",
    "] = np.nan\n",
    "\n",
    "df_results[\"Timepoint\"] = np.NaN\n",
    "df_results.loc[df_results[\"time\"] == 0.0, \"Timepoint\"] = \"0h\"\n",
    "df_results.loc[df_results[\"time\"] == 0.33, \"Timepoint\"] = \"24h\"\n",
    "df_results.loc[df_results[\"time\"] == 0.67, \"Timepoint\"] = \"48h\"\n",
    "df_results.loc[df_results[\"time\"] == 1.0, \"Timepoint\"] = \"72h\"\n",
    "\n",
    "# Merge score_activation_new into df_results\n",
    "df_results = df_results.merge(\n",
    "    adata.obs[[\"treatment\", \"Timepoint\", \"score_activation_new\"]],\n",
    "    left_on=[\"treatment\", \"Timepoint\"],\n",
    "    right_on=[\"treatment\", \"Timepoint\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 5))\n",
    "for idx, group in enumerate([\"weak\", \"small\", \"medium\", \"strong\"]):\n",
    "    sns.boxplot(\n",
    "        data=df_results.loc[(df_results[\"group\"] == group) & (df_results[\"time\"] > 0.0)],\n",
    "        x=\"time\",\n",
    "        y=select_by.replace(\"_mean\", \"\"),\n",
    "        hue=\"model\",\n",
    "        ax=ax[idx],\n",
    "        legend=True,\n",
    "        showfliers=False,\n",
    "    )\n",
    "    ax[idx].set_title(f\"Treatment effect: {group}\")\n",
    "plt.tight_layout()\n",
    "# Create a single legend for the figure\n",
    "handles, labels = fig.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(\n",
    "    by_label.values(),\n",
    "    by_label.keys(),\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1.0, 0.5),\n",
    "    handler_map={plt.Line2D: ThickerLine2D()},\n",
    "    title=\"Model\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "for k in range(4):\n",
    "    ax[k].set_xlabel(\"Timepoint\")\n",
    "    ax[k].set_ylabel(\"EMD\")\n",
    "    ax[k].grid(axis=\"y\")\n",
    "    # Remove legend from ax[2]\n",
    "    ax[k].legend().remove()\n",
    "plt.savefig(f\"../../figures_paper/iccite_timecourse.png\")\n",
    "# plt.close()\n",
    "# Add vertical lines between the on the right side of the boxplot\n",
    "for k in range(4):\n",
    "    for i in range(3):\n",
    "        ax[k].axvline(i - 0.5, color=\"black\", lw=1, alpha=0.25, linestyle=\"--\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5), sharey=False, sharex=True)\n",
    "df_results[\"binned_score_activation_new\"] = pd.cut(\n",
    "    df_results[\"score_activation_new\"],\n",
    "    bins=[-np.inf, -0.1, 0.1, 0.3, 0.5, np.inf],\n",
    "    labels=[\"low\", \"medium-low\", \"medium\", \"medium-high\", \"high\"],\n",
    ")\n",
    "sns.boxplot(\n",
    "    data=df_results.loc[(~df_results[\"training\"]) & (df_results[\"time\"] == 0.33)],\n",
    "    x=\"binned_score_activation_new\",\n",
    "    y=select_by.replace(\"_mean\", \"\"),\n",
    "    hue=\"model\",\n",
    "    ax=ax[0],\n",
    "    legend=False,\n",
    "    showfliers=False,\n",
    ")\n",
    "sns.boxplot(\n",
    "    data=df_results.loc[(~df_results[\"training\"]) & (df_results[\"time\"] == 0.67)],\n",
    "    x=\"binned_score_activation_new\",\n",
    "    y=select_by.replace(\"_mean\", \"\"),\n",
    "    hue=\"model\",\n",
    "    ax=ax[1],\n",
    "    legend=False,\n",
    "    showfliers=False,\n",
    ")\n",
    "\n",
    "sns.boxplot(\n",
    "    data=df_results.loc[(~df_results[\"training\"]) & (df_results[\"time\"] == 1.0)],\n",
    "    x=\"binned_score_activation_new\",\n",
    "    y=select_by.replace(\"_mean\", \"\"),\n",
    "    hue=\"model\",\n",
    "    ax=ax[2],\n",
    "    legend=True,\n",
    "    showfliers=False,\n",
    ")\n",
    "# Add vertical lines between the on the right side of the boxplot\n",
    "for k in range(3):\n",
    "    for i in range(5):\n",
    "        ax[k].axvline(i - 0.5, color=\"black\", lw=1, alpha=0.25, linestyle=\"--\")\n",
    "\n",
    "\n",
    "# Create a single legend for the figure\n",
    "handles, labels = fig.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(\n",
    "    by_label.values(),\n",
    "    by_label.keys(),\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1.0, 0.5),\n",
    "    handler_map={plt.Line2D: ThickerLine2D()},\n",
    "    title=\"Model\",\n",
    ")\n",
    "\n",
    "ax[0].set_title(\"Timepoint: 24h\")\n",
    "ax[1].set_title(\"Timepoint: 48h\")\n",
    "ax[2].set_title(\"Timepoint: 72h\")\n",
    "plt.tight_layout()\n",
    "for k in range(3):\n",
    "    ax[k].set_xlabel(\"Gene Activation Level\")\n",
    "    ax[k].set_ylabel(\"EMD\")\n",
    "    # Rotate x axis ticks for better readability\n",
    "    ax[k].set_xticklabels(ax[k].get_xticklabels(), rotation=45)\n",
    "    # Set legend title to Model\n",
    "    # ax[k].legend(title=\"Model\")\n",
    "    ax[k].grid(axis=\"y\")\n",
    "# Remove legend from ax[2]\n",
    "ax[2].legend().remove()\n",
    "\n",
    "plt.savefig(f\"../../figures_paper/iccite_gene_activation.png\")\n",
    "# plt.close()\n",
    "plt.show()\n",
    "\n",
    "# Wasserstein metric\n",
    "# dgp_iccite_a_0_0.001_0.1_3_False_0.0_64_64_64_True_False_free_False_False_None_False_True_xavier_SELU_cosine_cubic_300_cot_None_0.8_None_10_100_None_adam_None_None_None_a_False_0.0_False_False_emd_mmfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = (\n",
    "    df_results.groupby([\"model\", \"training\", \"time\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"mmd\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mmd_median\": [\"mean\", \"std\", \"max\"],\n",
    "            \"wasserstein\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mean_diff_l1\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mean_diff_l2\": [\"mean\", \"std\", \"max\"],\n",
    "        }\n",
    "    )\n",
    "    .round(2)\n",
    "    .rename(columns={\"model\": \"Model\"})[[\"mean_diff_l2\", \"wasserstein\"]]\n",
    "    .reset_index()\n",
    ")\n",
    "df_r = df_r.loc[~df_r[\"training\"]]\n",
    "df_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
