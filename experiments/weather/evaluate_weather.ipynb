{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations DGP Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from addict import Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "import cloudpickle\n",
    "\n",
    "from mmfm.data import dgp_beijing_data\n",
    "from mmfm.trajectory import sample_trajectory\n",
    "from mmfm.evaluation import compute_metric_set\n",
    "from mmfm.models import VectorFieldModel, MultiVectorFieldModel, MultiVectorFieldModelTCFM\n",
    "from mmfm.utils_eval import (\n",
    "    load_all_fm_models,\n",
    "    process_all_fm_models,\n",
    "    # predict_on_testset_fsi,\n",
    ")\n",
    "from mmfm.utils import color_picker, create_plot_grid, COLORMAP10, ThickerLine2D, COLORMAP12\n",
    "\n",
    "# # Plotting settings\n",
    "# params = {\n",
    "#     \"axes.labelsize\": 18,\n",
    "#     \"axes.titlesize\": 22,\n",
    "#     \"xtick.labelsize\": 18,\n",
    "#     \"ytick.labelsize\": 18,\n",
    "#     \"legend.fontsize\": 18,\n",
    "#     \"legend.title_fontsize\": 18,\n",
    "#     \"figure.titlesize\": 30,\n",
    "# }\n",
    "# plt.rcParams.update(params)\n",
    "# plt.style.use([\"science\", \"no-latex\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROD = True\n",
    "minimum_seeds = 1\n",
    "dimension = 1\n",
    "batch_size = None\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "path_name_fsi = \"/data/m015k/results/dgp_weather/results_fsi\"\n",
    "verbose = False\n",
    "\n",
    "# Data\n",
    "DGP = \"a\"\n",
    "label_list = list(np.linspace(1, 12, 12, endpoint=True))\n",
    "\n",
    "ns_per_t_and_c = 50\n",
    "coupling = \"cot\"\n",
    "train_test_split = 0.5\n",
    "embedding_type = \"free\"\n",
    "classifier_free = False\n",
    "\n",
    "n_top_models = 1\n",
    "n_top_seeds = 1\n",
    "model_string = \"dgp_weather\"\n",
    "average_out_seed = False\n",
    "select_by = \"mean_diff_l2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_models(prod, dgp, load_parquet=True, coupling=None, embedding_type=None, filter_values=None):\n",
    "    if load_parquet & (Path(\"data\") / f\"df_gt_{dgp}.parquet\").exists():\n",
    "        # This file contains all model train and validation results in a tidy format\n",
    "        # i.e., each row corresponds to a single model run (model, seed, guidance, etc.)\n",
    "        df = pd.read_parquet(Path(\"data\") / f\"df_gt_{dgp}.parquet\")\n",
    "        # Try to convert each value in column flow_variance to float if possible, otherwise leave value as string\n",
    "        try:\n",
    "            df[\"flow_variance\"] = df[\"flow_variance\"].astype(float)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        with open(Path(\"data\") / f\"grouping_columns_{dgp}.pkl\", \"rb\") as f:\n",
    "            grouping_columns = pickle.load(f)\n",
    "        with open(Path(\"data\") / f\"performance_columns_{dgp}.pkl\", \"rb\") as f:\n",
    "            performance_columns = pickle.load(f)\n",
    "    else:\n",
    "        df, grouping_columns, performance_columns = load_all_fm_models(\n",
    "            path=\"/data/m015k/results/dgp_weather/results_mmfm\",\n",
    "            production=prod,  # If prod is false, only load a small subset of data\n",
    "            dgp=DGP,\n",
    "            coupling=coupling,\n",
    "            embedding_type=embedding_type,\n",
    "            filter_values=filter_values,\n",
    "        )\n",
    "\n",
    "        # Filter for only validation results\n",
    "        df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "        df = df.loc[~df[\"train\"]]\n",
    "\n",
    "        # Save everything\n",
    "        # Convert\n",
    "        df[\"flow_variance\"] = df[\"flow_variance\"].astype(str)\n",
    "        print(f\"Saving data with shape {df.shape}\")\n",
    "        df.to_parquet(Path(\"data\") / f\"df_gt_{dgp}.parquet\")\n",
    "        # Try to convert each value in column flow_variance to float if possible, otherwise leave value as string\n",
    "        try:\n",
    "            df[\"flow_variance\"] = df[\"flow_variance\"].astype(float)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        with open(Path(\"data\") / f\"grouping_columns_{dgp}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(grouping_columns, f)\n",
    "        with open(Path(\"data\") / f\"performance_columns_{dgp}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(performance_columns, f)\n",
    "\n",
    "    return df, grouping_columns, performance_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess all MMFM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2006/2006 [00:10<00:00, 188.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data with shape (743496, 32)\n"
     ]
    }
   ],
   "source": [
    "df, grouping_columns, performance_columns = load_all_models(\n",
    "    PROD, DGP, load_parquet=False, coupling=coupling, embedding_type=embedding_type, filter_values=\"mmfm\"\n",
    ")\n",
    "model_type = \"mmfm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data before filtering: (743496, 32)\n",
      "Data after 1st filtering: (305136, 32)\n",
      "Number of models before adjusting for seeds: 305136\n",
      "Number of models after adjusting for seeds:  305136\n",
      "\n",
      "Dropping column seed with only one unique value: 0\n",
      "- Skipping column ns_per_t_and_c\n",
      "- Skipping column embedding_type\n",
      "Dropping column normalization with only one unique value: None\n",
      "Dropping column n_classes with only one unique value: 12\n",
      "- Skipping column interpolation\n",
      "Dropping column conditional_model with only one unique value: True\n",
      "- Skipping column classifier_free\n",
      "- Skipping column coupling\n",
      "Dropping column train_test_split with only one unique value: 0.5\n",
      "- Skipping column dgp\n",
      "Dropping column conditional_bias with only one unique value: False\n",
      "Dropping column model_type with only one unique value: mmfm\n",
      "Dropping column matching with only one unique value: emd\n",
      "- Skipping column guidance\n",
      "Dropping column train with only one unique value: False\n",
      "Dropping column kl_div with only one unique value: nan\n",
      "Data after 2nd filtering: (305136, 22)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data before filtering: {df.shape}\")\n",
    "\n",
    "df = df.loc[\n",
    "    (df[\"ns_per_t_and_c\"] == ns_per_t_and_c)\n",
    "    & (df[\"coupling\"] == coupling)\n",
    "    & (df[\"train_test_split\"] == train_test_split)\n",
    "    & (df[\"embedding_type\"] == embedding_type)\n",
    "    & (df[\"model_type\"] == model_type)\n",
    "]\n",
    "if not classifier_free:\n",
    "    df = df.loc[~df[\"classifier_free\"]]\n",
    "\n",
    "# Filter for only validation results\n",
    "df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "df = df.loc[~df[\"train\"]]\n",
    "\n",
    "df = df.loc[(df[\"interpolation\"] == \"cubic\")]\n",
    "\n",
    "print(f\"Data after 1st filtering: {df.shape}\")\n",
    "\n",
    "df, grouping_columns, performance_columns = process_all_fm_models(\n",
    "    df,\n",
    "    grouping_columns,\n",
    "    performance_columns,\n",
    "    plot=False,\n",
    "    verbose=True,\n",
    "    minimum_seeds=minimum_seeds,\n",
    "    data_cols=[\n",
    "        \"ns_per_t_and_c\",\n",
    "        \"coupling\",\n",
    "        \"dgp\",\n",
    "        \"interpolation\",\n",
    "        \"guidance\",\n",
    "        \"embedding_type\",\n",
    "        \"classifier_free\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Data after 2nd filtering: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best model on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_battery_of_best_models_wc(\n",
    "    df, select_by, n_top_seeds, model_string, dgp, average_out_seed=True, verbose=False, selector=\"mean\", model=None\n",
    "):\n",
    "    \"\"\"Find best model according to a given metric and return the model battery of the best model.\n",
    "\n",
    "    We use either use mean or max statistics on the holdout validation data to select the best model.\n",
    "    \"\"\"\n",
    "\n",
    "    def weighted_avg(group_df, whole_df, values, weights):\n",
    "        v = whole_df.loc[group_df.index, values]\n",
    "        w = whole_df.loc[group_df.index, weights]\n",
    "        return (v * w).sum() / w.sum()\n",
    "\n",
    "    def weighted_max(group_df, whole_df, values, weights):\n",
    "        v = whole_df.loc[group_df.index, values]\n",
    "        w = whole_df.loc[group_df.index, weights]\n",
    "        return (v * w).max()\n",
    "\n",
    "    if average_out_seed:\n",
    "        grouping = [x for x in grouping_columns if x not in [\"marginal\", \"time\", \"seed\"]]\n",
    "    else:\n",
    "        grouping = [x for x in grouping_columns if x not in [\"marginal\", \"time\"]]\n",
    "\n",
    "    df_agg = (\n",
    "        (\n",
    "            df.drop(columns=[\"marginal\", \"time\"])\n",
    "            .groupby(grouping)\n",
    "            .agg(\n",
    "                scoring_mean=(select_by, lambda x: weighted_avg(x, df, select_by, \"weight\")),\n",
    "                scoring_max=(select_by, lambda x: weighted_max(x, df, select_by, \"weight\")),\n",
    "                filename_first=(\"filename\", \"first\"),\n",
    "            )\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"scoring_mean\": f\"{select_by}_mean\",\n",
    "                \"scoring_max\": f\"{select_by}_max\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Enumerate all filenames\n",
    "    map_filename_to_id = {filename: idx for idx, filename in enumerate(df_agg[\"filename_first\"].unique())}\n",
    "    df_agg[\"id\"] = df_agg[\"filename_first\"].map(map_filename_to_id)\n",
    "\n",
    "    # Average out everything except for id, c, guidance\n",
    "    df_agg2 = df_agg.groupby([\"id\", \"c\", \"guidance\"])[f\"{select_by}_{selector}\"].mean().reset_index()\n",
    "\n",
    "    # For each combination of c and id, find the guidance value where the mean_diff_l2_mean is lowest\n",
    "    guidances = df_agg2.loc[df_agg2.groupby([\"id\", \"c\"])[f\"{select_by}_{selector}\"].idxmin()]\n",
    "\n",
    "    # Compute best score across conditions for each model\n",
    "    guidances_scores = (\n",
    "        guidances.groupby([\"id\"])[f\"{select_by}_{selector}\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .sort_values(by=f\"{select_by}_{selector}\", ascending=True)\n",
    "    )\n",
    "\n",
    "    best_model_id = guidances_scores[\"id\"].iloc[0]\n",
    "    best_model = [x for x in df_agg[\"filename_first\"].unique() if map_filename_to_id[x] == best_model_id][0]\n",
    "\n",
    "    df_agg_c = df.loc[df[\"filename\"] == best_model, :]\n",
    "\n",
    "    model_battery = Dict()\n",
    "    model_guidances = Dict()\n",
    "    model_states = Dict()\n",
    "    gudiance_best_model = guidances[guidances.id == best_model_id]\n",
    "\n",
    "    for _, c in enumerate(df_agg_c[\"c\"].unique()):\n",
    "        model_guidances[c] = gudiance_best_model.loc[gudiance_best_model[\"c\"] == c, \"guidance\"].iloc[0]\n",
    "\n",
    "        # Load the model from its filename and all its seed-variations\n",
    "        model_path = best_model\n",
    "        model_path = model_path.replace(\"df_results.csv\", \"model.pt\")\n",
    "\n",
    "        # print(f\"Loading model from {model_path}\")\n",
    "\n",
    "        for seed in range(n_top_seeds):\n",
    "            # Replace \"dgp2_{seed}\" with \"dgp2_x\" in the path\n",
    "            current_seed = model_path.split(\"_\")[5]\n",
    "            model_path = model_path.replace(f\"{model_string}_{dgp}_{current_seed}\", f\"{model_string}_{dgp}_{seed}\")\n",
    "            filename = model_path.split(\"/\")[-2]\n",
    "\n",
    "            try:\n",
    "                state = torch.load(model_path, weights_only=True)\n",
    "                if verbose:\n",
    "                    print(f\"✓ {filename}\")\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                if verbose:\n",
    "                    print(f\"✗ {filename}\")\n",
    "                continue\n",
    "\n",
    "            if model is None:\n",
    "                mmfm_model = VectorFieldModel(\n",
    "                    data_dim=state[\"dimension\"] if \"dimension\" in state else state[\"use_pca\"],\n",
    "                    x_latent_dim=state[\"x_latent_dim\"],\n",
    "                    time_embed_dim=state[\"time_embed_dim\"],\n",
    "                    cond_embed_dim=state[\"cond_embed_dim\"],\n",
    "                    conditional_model=state[\"conditional_model\"],\n",
    "                    embedding_type=state[\"embedding_type\"],\n",
    "                    n_classes=state[\"n_classes\"],\n",
    "                    label_list=label_list,\n",
    "                    normalization=state[\"normalization\"],\n",
    "                    activation=state[\"activation\"],\n",
    "                    affine_transform=state[\"affine_transform\"],\n",
    "                    sum_time_embed=state[\"sum_time_embed\"],\n",
    "                    sum_cond_embed=state[\"sum_cond_embed\"],\n",
    "                    max_norm_embedding=state[\"max_norm_embedding\"],\n",
    "                    num_out_layers=state[\"num_out_layers\"],\n",
    "                    spectral_norm=state[\"spectral_norm\"],\n",
    "                    dropout=state[\"dropout\"],\n",
    "                    conditional_bias=state[\"conditional_bias\"],\n",
    "                    keep_constants=state[\"keep_constants\"],\n",
    "                ).to(device)\n",
    "            elif model == \"totcfm\":\n",
    "                mmfm_model = MultiVectorFieldModelTCFM(\n",
    "                    model_list=[0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                    data_dim=state[\"dimension\"],\n",
    "                    x_latent_dim=state[\"x_latent_dim\"],\n",
    "                    time_embed_dim=state[\"time_embed_dim\"],\n",
    "                    cond_embed_dim=state[\"cond_embed_dim\"],\n",
    "                    conditional_model=state[\"conditional_model\"],\n",
    "                    embedding_type=state[\"embedding_type\"],\n",
    "                    n_classes=state[\"n_classes\"],\n",
    "                    label_list=label_list,\n",
    "                    normalization=state[\"normalization\"],\n",
    "                    activation=state[\"activation\"],\n",
    "                    affine_transform=state[\"affine_transform\"],\n",
    "                    sum_time_embed=state[\"sum_time_embed\"],\n",
    "                    sum_cond_embed=state[\"sum_cond_embed\"],\n",
    "                    max_norm_embedding=state[\"max_norm_embedding\"],\n",
    "                    num_out_layers=state[\"num_out_layers\"],\n",
    "                    spectral_norm=state[\"spectral_norm\"],\n",
    "                    dropout=state[\"dropout\"],\n",
    "                    conditional_bias=state[\"conditional_bias\"],\n",
    "                    keep_constants=state[\"keep_constants\"],\n",
    "                ).to(device)\n",
    "            elif model == \"tcotcfm\":\n",
    "                mmfm_model = MultiVectorFieldModel(\n",
    "                    model_list={\n",
    "                        1: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        1.5: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        2: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        2.5: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        3: [0, 0.1, 0.5, 0.9, 1],\n",
    "                        3.5: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        4: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        4.5: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        5: [0, 0.3, 0.5, 0.7, 1],\n",
    "                        5.5: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        6: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        6.5: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                    },\n",
    "                    data_dim=state[\"dimension\"],\n",
    "                    x_latent_dim=state[\"x_latent_dim\"],\n",
    "                    time_embed_dim=state[\"time_embed_dim\"],\n",
    "                    cond_embed_dim=state[\"cond_embed_dim\"],\n",
    "                    conditional_model=state[\"conditional_model\"],\n",
    "                    embedding_type=state[\"embedding_type\"],\n",
    "                    n_classes=state[\"n_classes\"],\n",
    "                    label_list=label_list,\n",
    "                    normalization=state[\"normalization\"],\n",
    "                    activation=state[\"activation\"],\n",
    "                    affine_transform=state[\"affine_transform\"],\n",
    "                    sum_time_embed=state[\"sum_time_embed\"],\n",
    "                    sum_cond_embed=state[\"sum_cond_embed\"],\n",
    "                    max_norm_embedding=state[\"max_norm_embedding\"],\n",
    "                    num_out_layers=state[\"num_out_layers\"],\n",
    "                    spectral_norm=state[\"spectral_norm\"],\n",
    "                    dropout=state[\"dropout\"],\n",
    "                    conditional_bias=state[\"conditional_bias\"],\n",
    "                    keep_constants=state[\"keep_constants\"],\n",
    "                ).to(device)\n",
    "\n",
    "            mmfm_model.load_state_dict(state[\"state_dict\"], strict=True)\n",
    "            model_battery[seed] = mmfm_model\n",
    "            model_states[seed] = state\n",
    "\n",
    "    # Set guidance for all other c to 0\n",
    "    missing_c = set(df_agg_c[\"c\"].unique()) - set(df_agg[\"c\"].unique())\n",
    "    for c in missing_c:\n",
    "        model_guidances[c] = 0\n",
    "\n",
    "    return model_battery, model_guidances, model_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_models_wc(\n",
    "    trajectory,\n",
    "    ncols,\n",
    "    s,\n",
    "    coupling,\n",
    "    batch_size,\n",
    "    ns_per_t_and_c,\n",
    "    dgp,\n",
    "    seed=0,\n",
    "    save=False,\n",
    "    suffix=None,\n",
    "    already_subset=False\n",
    "):\n",
    "    \"\"\"Plot the trajectories of the best models for each condition c in a grid.\"\"\"\n",
    "    # We only load the train data, because we want to plot it in the background\n",
    "    from mmfm.data import dgp_beijing_data\n",
    "    _, X_train, y_train, t_train, _, _, _, n_classes, _ = dgp_beijing_data(\n",
    "        coupling, batch_size, ns_per_t_and_c, DGP, return_data=\"train-valid\"\n",
    "    )\n",
    "    t = t_train\n",
    "\n",
    "    fig, ax, ncols, _ = create_plot_grid(n_classes, ncols=ncols)\n",
    "\n",
    "    df = pd.DataFrame(X_train.reshape(-1, 1)).assign(target=y_train.reshape(-1, 1), time=t_train.reshape(-1, 1))\n",
    "    df.columns = [\"y\", \"target\", \"x\"]\n",
    "\n",
    "    color_classes = [int(x) for x in range(len([x for x in np.unique(y_train) if np.isfinite(x)]))]\n",
    "    colors = color_picker(color_classes)\n",
    "    non_nan_targets = [x for x in np.unique(y_train) if np.isfinite(x)]\n",
    "\n",
    "    # Plot backgrounds\n",
    "    s = 2\n",
    "    for k, c in enumerate(non_nan_targets):\n",
    "        axidx = ax[k // ncols, k % ncols]\n",
    "        sns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"target\", ax=axidx, legend=False, alpha=0.05, palette=colors, s=s)\n",
    "        sns.scatterplot(data=df[df[\"target\"] == c], x=\"x\", y=\"y\", ax=axidx, color=colors[k], s=15)\n",
    "        sns.lineplot(data=df[df[\"target\"] == c], x=\"x\", y=\"y\", ax=axidx, color=colors[k])\n",
    "        axidx.set_title(f\"Condition c={c}\")\n",
    "\n",
    "    # # Plot ground truth trajectories\n",
    "    # already_subset = False\n",
    "    # for k, c in enumerate(non_nan_targets):\n",
    "    #     if not already_subset:\n",
    "    #         idx_plot = np.where(y_train[:, 0] == c)[0][:2]\n",
    "    #     else:\n",
    "    #         idx_plot = [0, 1]\n",
    "    #     for n in idx_plot:\n",
    "    #         y0 = trajectory[c][seed][0, n]#, y_train[n, 0]\n",
    "    #         t = np.linspace(0, 1, 101)\n",
    "    #         sol = odeint(u, y0, t, args=(c,))\n",
    "    #         ax[k // ncols, k % ncols].plot(sol[:, 0], sol[:, 1], color=\"blue\", alpha=0.2, lw=7.5)\n",
    "\n",
    "    # Plot predicted marginals\n",
    "    # Plot ground truth trajectories\n",
    "    for k, c in enumerate(non_nan_targets):\n",
    "        if not already_subset:\n",
    "            idx_plot = np.where(y_train[:, 0] == c)[0][:2]\n",
    "        else:\n",
    "            idx_plot = [0, 1]\n",
    "\n",
    "        for n in idx_plot:\n",
    "            for i in range(len(trj[c][seed]) - 1):\n",
    "                ax[k // ncols, k % ncols].plot(\n",
    "                    [i/100, (i+1)/100],\n",
    "                    [trajectory[c][seed][i, n, 0], trajectory[c][seed][i + 1, n, 0]],\n",
    "                    color=\"black\",\n",
    "                    lw=2,\n",
    "                )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        fn = f\"/data/m015k/code/MMFM/figures_paper/trajectory_wave_{seed}_35.png\"\n",
    "        if suffix is not None:\n",
    "            fn = fn.replace(\".png\", f\"_{suffix}.png\")\n",
    "        plt.savefig(fn)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305136, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.16, 0.44, 0.52, 0.68, 0.92, 1.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add weight column to lay focus on conditional generalization\n",
    "df_cubic = df.copy()\n",
    "df_cubic.loc[:, \"weight\"] = 1\n",
    "\n",
    "print(df_cubic.shape)\n",
    "\n",
    "# this is our extra validation timepoint\n",
    "# Note, that for a fair comparison we provide this sample as training data to FSI\n",
    "add_time_cond = None  # (7, 0.15)\n",
    "\n",
    "# Create a new column \n",
    "timepoint_to_integer = {v: k for k,v in enumerate(sorted(df_cubic[\"time\"].unique()))}\n",
    "integer_to_timepoint = {k: v for k,v in enumerate(sorted(df_cubic[\"time\"].unique()))}\n",
    "df[\"timestep\"] = df[\"time\"].map(timepoint_to_integer)\n",
    "\n",
    "# Convert to timepoints\n",
    "timepoints = [0, 4, 11, 13, 17, 23, 25] #[0, 2, 4, 6, 7, 11, 12, 14, 16, 18, 19, 23, 25]\n",
    "timepoints = [float(integer_to_timepoint[x]) for x in timepoints]\n",
    "timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_608829/2441929112.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cubic_valid[\"weight\"] = 0.01\n"
     ]
    }
   ],
   "source": [
    "# Filtering for target validation time and c\n",
    "df_cubic_valid = df_cubic.loc[\n",
    "    ((df_cubic[\"c\"] == 4) & (df_cubic[\"time\"].isin([0.0, 0.2, 0.36, 0.4, 0.44, 0.68, 0.8, 1.0])))\n",
    "    | ((df_cubic[\"c\"] == 7) & (df_cubic[\"time\"].isin([0.0, 0.12, 0.52, 0.68, 0.8, 1.0])))\n",
    "    | ((df_cubic[\"c\"] == 10) & (df_cubic[\"time\"].isin([0.0, 0.16, 0.44, 0.52, 0.68, 0.92, 1.0])))\n",
    "    | ((df_cubic[\"c\"] != 4) & (df_cubic[\"c\"] != 7) & (df_cubic[\"c\"] != 10) & (df_cubic[\"time\"].isin([0.0, 0.08, 0.16, 0.24, 0.28, 0.44, 0.48, 0.56, 0.64, 0.72, 0.76, 0.92, 1.0])))\n",
    "]\n",
    "df_cubic_valid[\"weight\"] = 0.01\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"c\"] == 7) & (df_cubic_valid[\"time\"].isin([0.44])), \"weight\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>flow_variance</th>\n",
       "      <th>p_unconditional</th>\n",
       "      <th>ns_per_t_and_c</th>\n",
       "      <th>x_latent_dim</th>\n",
       "      <th>time_embed_dim</th>\n",
       "      <th>cond_embed_dim</th>\n",
       "      <th>embedding_type</th>\n",
       "      <th>interpolation</th>\n",
       "      <th>classifier_free</th>\n",
       "      <th>coupling</th>\n",
       "      <th>dgp</th>\n",
       "      <th>c</th>\n",
       "      <th>guidance</th>\n",
       "      <th>mean_diff_l2_mean</th>\n",
       "      <th>mean_diff_l2_max</th>\n",
       "      <th>filename_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>free</td>\n",
       "      <td>cubic</td>\n",
       "      <td>False</td>\n",
       "      <td>cot</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.350041</td>\n",
       "      <td>0.695736</td>\n",
       "      <td>/data/m015k/results/dgp_weather/results_mmfm/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>free</td>\n",
       "      <td>cubic</td>\n",
       "      <td>False</td>\n",
       "      <td>cot</td>\n",
       "      <td>a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.195339</td>\n",
       "      <td>0.535966</td>\n",
       "      <td>/data/m015k/results/dgp_weather/results_mmfm/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>free</td>\n",
       "      <td>cubic</td>\n",
       "      <td>False</td>\n",
       "      <td>cot</td>\n",
       "      <td>a</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.822182</td>\n",
       "      <td>0.467291</td>\n",
       "      <td>/data/m015k/results/dgp_weather/results_mmfm/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>free</td>\n",
       "      <td>cubic</td>\n",
       "      <td>False</td>\n",
       "      <td>cot</td>\n",
       "      <td>a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.113907</td>\n",
       "      <td>0.689685</td>\n",
       "      <td>/data/m015k/results/dgp_weather/results_mmfm/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>free</td>\n",
       "      <td>cubic</td>\n",
       "      <td>False</td>\n",
       "      <td>cot</td>\n",
       "      <td>a</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.454451</td>\n",
       "      <td>0.666768</td>\n",
       "      <td>/data/m015k/results/dgp_weather/results_mmfm/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11731</th>\n",
       "      <td>0.020</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>free</td>\n",
       "      <td>cubic</td>\n",
       "      <td>False</td>\n",
       "      <td>cot</td>\n",
       "      <td>a</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>29.793422</td>\n",
       "      <td>0.869918</td>\n",
       "      <td>/data/m015k/results/dgp_weather/results_mmfm/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11732</th>\n",
       "      <td>0.020</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>free</td>\n",
       "      <td>cubic</td>\n",
       "      <td>False</td>\n",
       "      <td>cot</td>\n",
       "      <td>a</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.780660</td>\n",
       "      <td>0.868189</td>\n",
       "      <td>/data/m015k/results/dgp_weather/results_mmfm/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11733</th>\n",
       "      <td>0.020</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>free</td>\n",
       "      <td>cubic</td>\n",
       "      <td>False</td>\n",
       "      <td>cot</td>\n",
       "      <td>a</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>29.717096</td>\n",
       "      <td>0.859550</td>\n",
       "      <td>/data/m015k/results/dgp_weather/results_mmfm/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11734</th>\n",
       "      <td>0.020</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>free</td>\n",
       "      <td>cubic</td>\n",
       "      <td>False</td>\n",
       "      <td>cot</td>\n",
       "      <td>a</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.653310</td>\n",
       "      <td>0.850879</td>\n",
       "      <td>/data/m015k/results/dgp_weather/results_mmfm/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11735</th>\n",
       "      <td>0.020</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>free</td>\n",
       "      <td>cubic</td>\n",
       "      <td>False</td>\n",
       "      <td>cot</td>\n",
       "      <td>a</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.660422</td>\n",
       "      <td>0.833404</td>\n",
       "      <td>/data/m015k/results/dgp_weather/results_mmfm/d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11736 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lr  flow_variance  p_unconditional  ns_per_t_and_c  x_latent_dim  \\\n",
       "0      0.001          0.001              0.0              50             8   \n",
       "1      0.001          0.001              0.0              50             8   \n",
       "2      0.001          0.001              0.0              50             8   \n",
       "3      0.001          0.001              0.0              50             8   \n",
       "4      0.001          0.001              0.0              50             8   \n",
       "...      ...            ...              ...             ...           ...   \n",
       "11731  0.020          1.000              0.1              50             8   \n",
       "11732  0.020          1.000              0.1              50             8   \n",
       "11733  0.020          1.000              0.1              50             8   \n",
       "11734  0.020          1.000              0.1              50             8   \n",
       "11735  0.020          1.000              0.1              50             8   \n",
       "\n",
       "       time_embed_dim  cond_embed_dim embedding_type interpolation  \\\n",
       "0                   8               8           free         cubic   \n",
       "1                   8               8           free         cubic   \n",
       "2                   8               8           free         cubic   \n",
       "3                   8               8           free         cubic   \n",
       "4                   8               8           free         cubic   \n",
       "...               ...             ...            ...           ...   \n",
       "11731               8               8           free         cubic   \n",
       "11732               8               8           free         cubic   \n",
       "11733               8               8           free         cubic   \n",
       "11734               8               8           free         cubic   \n",
       "11735               8               8           free         cubic   \n",
       "\n",
       "       classifier_free coupling dgp     c  guidance  mean_diff_l2_mean  \\\n",
       "0                False      cot   a   1.0       1.0          25.350041   \n",
       "1                False      cot   a   2.0       1.0          30.195339   \n",
       "2                False      cot   a   3.0       1.0          24.822182   \n",
       "3                False      cot   a   4.0       1.0          26.113907   \n",
       "4                False      cot   a   5.0       1.0          26.454451   \n",
       "...                ...      ...  ..   ...       ...                ...   \n",
       "11731            False      cot   a  12.0       0.9          29.793422   \n",
       "11732            False      cot   a  12.0       1.0          29.780660   \n",
       "11733            False      cot   a  12.0       1.5          29.717096   \n",
       "11734            False      cot   a  12.0       2.0          29.653310   \n",
       "11735            False      cot   a  12.0       3.0          29.660422   \n",
       "\n",
       "       mean_diff_l2_max                                     filename_first  \n",
       "0              0.695736  /data/m015k/results/dgp_weather/results_mmfm/d...  \n",
       "1              0.535966  /data/m015k/results/dgp_weather/results_mmfm/d...  \n",
       "2              0.467291  /data/m015k/results/dgp_weather/results_mmfm/d...  \n",
       "3              0.689685  /data/m015k/results/dgp_weather/results_mmfm/d...  \n",
       "4              0.666768  /data/m015k/results/dgp_weather/results_mmfm/d...  \n",
       "...                 ...                                                ...  \n",
       "11731          0.869918  /data/m015k/results/dgp_weather/results_mmfm/d...  \n",
       "11732          0.868189  /data/m015k/results/dgp_weather/results_mmfm/d...  \n",
       "11733          0.859550  /data/m015k/results/dgp_weather/results_mmfm/d...  \n",
       "11734          0.850879  /data/m015k/results/dgp_weather/results_mmfm/d...  \n",
       "11735          0.833404  /data/m015k/results/dgp_weather/results_mmfm/d...  \n",
       "\n",
       "[11736 rows x 17 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df, select_by, n_top_seeds, model_string, dgp, average_out_seed=True, verbose=False, selector=\"mean\", model=None\n",
    "df = df_cubic_valid\n",
    "dgp = DGP\n",
    "average_out_seed=True\n",
    "selector=\"mean\"\n",
    "\n",
    "def weighted_avg(group_df, whole_df, values, weights):\n",
    "    v = whole_df.loc[group_df.index, values]\n",
    "    w = whole_df.loc[group_df.index, weights]\n",
    "    return (v * w).sum() / w.sum()\n",
    "\n",
    "def weighted_max(group_df, whole_df, values, weights):\n",
    "    v = whole_df.loc[group_df.index, values]\n",
    "    w = whole_df.loc[group_df.index, weights]\n",
    "    return (v * w).max()\n",
    "\n",
    "if average_out_seed:\n",
    "    grouping = [x for x in grouping_columns if x not in [\"marginal\", \"time\", \"seed\"]]\n",
    "else:\n",
    "    grouping = [x for x in grouping_columns if x not in [\"marginal\", \"time\"]]\n",
    "\n",
    "df_agg = (\n",
    "    (\n",
    "        df.drop(columns=[\"marginal\", \"time\"])\n",
    "        .groupby(grouping)\n",
    "        .agg(\n",
    "            scoring_mean=(select_by, lambda x: weighted_avg(x, df, select_by, \"weight\")),\n",
    "            scoring_max=(select_by, lambda x: weighted_max(x, df, select_by, \"weight\")),\n",
    "            filename_first=(\"filename\", \"first\"),\n",
    "        )\n",
    "    )\n",
    "    .reset_index()\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"scoring_mean\": f\"{select_by}_mean\",\n",
    "            \"scoring_max\": f\"{select_by}_max\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate all filenames\n",
    "map_filename_to_id = {filename: idx for idx, filename in enumerate(df_agg[\"filename_first\"].unique())}\n",
    "df_agg[\"id\"] = df_agg[\"filename_first\"].map(map_filename_to_id)\n",
    "\n",
    "# Average out everything except for id, c, guidance\n",
    "df_agg2 = df_agg.groupby([\"id\", \"c\", \"guidance\"])[f\"{select_by}_{selector}\"].mean().reset_index()\n",
    "\n",
    "# For each combination of c and id, find the guidance value where the mean_diff_l2_mean is lowest\n",
    "guidances = df_agg2.loc[df_agg2.groupby([\"id\", \"c\"])[f\"{select_by}_{selector}\"].idxmin()]\n",
    "\n",
    "# Compute best score across conditions for each model\n",
    "guidances_scores = (\n",
    "    guidances.groupby([\"id\"])[f\"{select_by}_{selector}\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(by=f\"{select_by}_{selector}\", ascending=True)\n",
    ")\n",
    "\n",
    "best_model_id = guidances_scores[\"id\"].iloc[0]\n",
    "best_model = [x for x in df_agg[\"filename_first\"].unique() if map_filename_to_id[x] == best_model_id][0]\n",
    "\n",
    "df_agg_c = df.loc[df[\"filename\"] == best_model, :]\n",
    "\n",
    "model_battery = Dict()\n",
    "model_guidances = Dict()\n",
    "model_states = Dict()\n",
    "gudiance_best_model = guidances[guidances.id == best_model_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>c</th>\n",
       "      <th>guidance</th>\n",
       "      <th>mean_diff_l2_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.741048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.619578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.423216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.884777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.441392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11661</th>\n",
       "      <td>717</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.315056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11662</th>\n",
       "      <td>717</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.451749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11663</th>\n",
       "      <td>717</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>10.134747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11664</th>\n",
       "      <td>717</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.274200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11665</th>\n",
       "      <td>717</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.589288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>978 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    c  guidance  mean_diff_l2_mean\n",
       "6        0  7.0       1.0          16.741048\n",
       "18       1  7.0       1.0          17.619578\n",
       "30       2  7.0       1.0          19.423216\n",
       "42       3  7.0       1.0          13.884777\n",
       "54       4  7.0       1.0          18.441392\n",
       "...    ...  ...       ...                ...\n",
       "11661  717  7.0       0.9           9.315056\n",
       "11662  717  7.0       1.0           9.451749\n",
       "11663  717  7.0       1.5          10.134747\n",
       "11664  717  7.0       2.0          11.274200\n",
       "11665  717  7.0       3.0          14.589288\n",
       "\n",
       "[978 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg2.loc[(df_agg2.c == 7) & (df_agg2.c != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>c</th>\n",
       "      <th>guidance</th>\n",
       "      <th>mean_diff_l2_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11556</th>\n",
       "      <td>716</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.691085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11557</th>\n",
       "      <td>716</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.660564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11558</th>\n",
       "      <td>716</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.418133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11559</th>\n",
       "      <td>716</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.844399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11560</th>\n",
       "      <td>716</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>716</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.231528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11562</th>\n",
       "      <td>716</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.966516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11563</th>\n",
       "      <td>716</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.656654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11564</th>\n",
       "      <td>716</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.270296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11565</th>\n",
       "      <td>716</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.711090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11566</th>\n",
       "      <td>716</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.537412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11567</th>\n",
       "      <td>716</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.181165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     c  guidance  mean_diff_l2_mean\n",
       "11556  716   1.0       1.0           8.691085\n",
       "11557  716   2.0       1.0           1.660564\n",
       "11558  716   3.0       1.0           1.418133\n",
       "11559  716   4.0       1.0           3.844399\n",
       "11560  716   5.0       1.0           0.960041\n",
       "11561  716   6.0       1.0           6.231528\n",
       "11562  716   7.0       1.0           3.966516\n",
       "11563  716   8.0       1.0           1.656654\n",
       "11564  716   9.0       1.0           2.270296\n",
       "11565  716  10.0       1.0           6.711090\n",
       "11566  716  11.0       1.0           1.537412\n",
       "11567  716  12.0       1.0           4.181165"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gudiance_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, c in enumerate(df_agg_c[\"c\"].unique()):\n",
    "    model_guidances[c] = gudiance_best_model.loc[gudiance_best_model[\"c\"] == c, \"guidance\"].iloc[0]\n",
    "\n",
    "    # Load the model from its filename and all its seed-variations\n",
    "    model_path = best_model\n",
    "    model_path = model_path.replace(\"df_results.csv\", \"model.pt\")\n",
    "\n",
    "    # print(f\"Loading model from {model_path}\")\n",
    "\n",
    "    for seed in range(n_top_seeds):\n",
    "        # Replace \"dgp2_{seed}\" with \"dgp2_x\" in the path\n",
    "        current_seed = model_path.split(\"_\")[5]\n",
    "        model_path = model_path.replace(f\"{model_string}_{dgp}_{current_seed}\", f\"{model_string}_{dgp}_{seed}\")\n",
    "        filename = model_path.split(\"/\")[-2]\n",
    "\n",
    "        try:\n",
    "            state = torch.load(model_path, weights_only=True)\n",
    "            if verbose:\n",
    "                print(f\"✓ {filename}\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            if verbose:\n",
    "                print(f\"✗ {filename}\")\n",
    "            continue\n",
    "\n",
    "        if model is None:\n",
    "            mmfm_model = VectorFieldModel(\n",
    "                data_dim=state[\"dimension\"] if \"dimension\" in state else state[\"use_pca\"],\n",
    "                x_latent_dim=state[\"x_latent_dim\"],\n",
    "                time_embed_dim=state[\"time_embed_dim\"],\n",
    "                cond_embed_dim=state[\"cond_embed_dim\"],\n",
    "                conditional_model=state[\"conditional_model\"],\n",
    "                embedding_type=state[\"embedding_type\"],\n",
    "                n_classes=state[\"n_classes\"],\n",
    "                label_list=label_list,\n",
    "                normalization=state[\"normalization\"],\n",
    "                activation=state[\"activation\"],\n",
    "                affine_transform=state[\"affine_transform\"],\n",
    "                sum_time_embed=state[\"sum_time_embed\"],\n",
    "                sum_cond_embed=state[\"sum_cond_embed\"],\n",
    "                max_norm_embedding=state[\"max_norm_embedding\"],\n",
    "                num_out_layers=state[\"num_out_layers\"],\n",
    "                spectral_norm=state[\"spectral_norm\"],\n",
    "                dropout=state[\"dropout\"],\n",
    "                conditional_bias=state[\"conditional_bias\"],\n",
    "                keep_constants=state[\"keep_constants\"],\n",
    "            ).to(device)\n",
    "\n",
    "        mmfm_model.load_state_dict(state[\"state_dict\"], strict=True)\n",
    "        model_battery[seed] = mmfm_model\n",
    "        model_states[seed] = state\n",
    "\n",
    "# Set guidance for all other c to 0\n",
    "missing_c = set(df_agg_c[\"c\"].unique()) - set(df_agg[\"c\"].unique())\n",
    "for c in missing_c:\n",
    "    model_guidances[c] = 0\n",
    "\n",
    "return model_battery, model_guidances, model_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_battery, model_guidances, model_states = get_model_battery_of_best_models_wc(\n",
    "    df_cubic_valid, select_by, n_top_seeds, model_string, DGP, average_out_seed=True, selector=\"mean\"\n",
    ")\n",
    "\n",
    "X_test, y_test, t_test, n_classes, timepoints, all_classes = dgp_beijing_data(\n",
    "    coupling, batch_size, ns_per_t_and_c, dgp=DGP, return_data=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results_mmfm = Dict()\n",
    "trajectories_test_mmfm = Dict()\n",
    "\n",
    "for seed, model in tqdm(model_battery.items()):\n",
    "    results = []\n",
    "    for idx, c in enumerate(label_list):\n",
    "        trajectories_test_mmfm[c][seed] = sample_trajectory(\n",
    "            model,\n",
    "            X=X_test[:, 0],\n",
    "            y=y_test[:, 0],\n",
    "            device=device,\n",
    "            guidance=model_guidances[c],  # if model_guidances.get(c) else 1,\n",
    "            conditional_model=model_states[seed][\"conditional_model\"],\n",
    "            rtol=1e-7,\n",
    "            atol=1e-9,\n",
    "            steps=101,\n",
    "            method=\"rk4\",\n",
    "        )\n",
    "\n",
    "        trajectory = np.swapaxes(trajectories_test_mmfm[c][seed], 0, 1)\n",
    "        trajectory = trajectory[\n",
    "            np.arange(trajectory.shape[0])[:, None], (t_test * (trajectory.shape[1] - 1)).astype(int)\n",
    "        ]\n",
    "\n",
    "        for marginal in range(trajectory.shape[1]):\n",
    "            target = X_test[:, marginal][y_test[:, marginal] == c]\n",
    "            transport = trajectory[:, marginal][y_test[:, 0] == c]\n",
    "            mmd, mmd_median, wasserstein, mean_diff_l1, mean_diff_l2, kl_div = compute_metric_set(target, transport)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"marginal\": marginal,\n",
    "                    \"c\": c,\n",
    "                    \"mmd\": mmd,\n",
    "                    \"mmd_median\": mmd_median,\n",
    "                    \"wasserstein\": wasserstein,\n",
    "                    \"guidance\": model_guidances[c],\n",
    "                    \"train\": False,\n",
    "                    \"time\": t_test[0, marginal],\n",
    "                    \"mean_diff_l1\": mean_diff_l1,\n",
    "                    \"mean_diff_l2\": mean_diff_l2,\n",
    "                    \"kl_div\": kl_div,\n",
    "                    \"seed\": seed,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_mmfm[seed] = pd.DataFrame(results)\n",
    "\n",
    "df_cubic_results_mmfm = pd.concat([results_mmfm[seed] for seed in results_mmfm], axis=0)\n",
    "df_cubic_results_mmfm[\"model\"] = \"COT-MMFM\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for seed in range(3):\n",
    "    try:\n",
    "        plot_models_wc(\n",
    "            trajectories_test_mmfm,\n",
    "            6,\n",
    "            20,\n",
    "            coupling,\n",
    "            batch_size,\n",
    "            ns_per_t_and_c,\n",
    "            DGP,\n",
    "            seed,\n",
    "            save=True,\n",
    "        )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average conditional trajectories for each condition\n",
    "trj = {\n",
    "    c: np.mean([trajectories_test_mmfm[c][seed] for seed in trajectories_test_mmfm[c].keys()], axis=0)\n",
    "    for c in label_list\n",
    "}\n",
    "for c in trj.keys():\n",
    "    trj[c] = {0: trj[c]}\n",
    "\n",
    "plot_models_wc(\n",
    "    trj, 6, 20, coupling, batch_size, ns_per_t_and_c, DGP, 0, save=False, suffix=\"avg\", already_subset=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cubic_results_mmfm.loc[df_cubic_results_mmfm[\"c\"] == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_train, y_train, t_train, _, _, _, n_classes, _ = dgp_beijing_data(\n",
    "        coupling, batch_size, ns_per_t_and_c, DGP, return_data=\"train-valid\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(20, 5), sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "def plot_background(ax, X, y, t, arrows=False, legend=False):\n",
    "    df = pd.DataFrame(X.reshape(-1, 2)).assign(condition=y.reshape(-1, 1), time=t.reshape(-1, 1))\n",
    "    df.columns = [\"x\", \"y\", \"condition\", \"time\"]\n",
    "    df = df.loc[~df[\"condition\"].isna()]\n",
    "    sns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"condition\", ax=ax, s=10, palette=COLORMAP12, legend=legend)\n",
    "    if arrows:\n",
    "        for c in label_list:\n",
    "            t = np.linspace(0, 1, 101)\n",
    "            sol = odeint(u, (0, (c - 1) / 2), t, args=(c,))\n",
    "            ax.plot(sol[:, 0], sol[:, 1], color=\"gray\", alpha=0.5, lw=2)\n",
    "            for idx in [20, 40, 60, 80]:\n",
    "                ax.arrow(\n",
    "                    sol[idx, 0],\n",
    "                    sol[idx, 1],\n",
    "                    sol[idx + 1, 0] - sol[idx, 0],\n",
    "                    sol[idx + 1, 1] - sol[idx, 1],\n",
    "                    color=\"gray\",\n",
    "                    alpha=0.25,\n",
    "                    head_width=0.05,\n",
    "                    head_length=0.05,\n",
    "                    fc=\"black\",\n",
    "                    ec=\"black\",\n",
    "                )\n",
    "    return ax\n",
    "\n",
    "\n",
    "#\n",
    "# Figure 1 is true vector field and measurements\n",
    "#\n",
    "add_time_cond = [(i, 0.15) for i in label_list]\n",
    "train_loader, X_train, y_train, t_train, X_valid, y_valid, t_valid, n_classes, label_list = dgp_waves_data(\n",
    "    coupling,\n",
    "    batch_size,\n",
    "    dimension,\n",
    "    off_diagonal,\n",
    "    data_std,\n",
    "    ns_per_t_and_c,\n",
    "    dgp=DGP,\n",
    "    return_data=\"train-valid\",\n",
    "    add_time_cond=add_time_cond,\n",
    "    filter_beginning_end=False,\n",
    ")\n",
    "ax[0] = plot_background(ax[0], X_train, y_train, t_train, arrows=True)\n",
    "ax[0].set_title(\"True Vector Field (Phase Diagram)\\nwith Training Data\", fontsize=18)\n",
    "\n",
    "\n",
    "#\n",
    "# Figure 2 shows FSI interpolation\n",
    "#\n",
    "add_time_cond = [(i, 0.15) for i in label_list]\n",
    "train_loader, X_train, y_train, t_train, X_valid, y_valid, t_valid, n_classes, label_list = dgp_waves_data(\n",
    "    coupling,\n",
    "    batch_size,\n",
    "    dimension,\n",
    "    off_diagonal,\n",
    "    data_std,\n",
    "    ns_per_t_and_c,\n",
    "    dgp=DGP,\n",
    "    return_data=\"train-valid\",\n",
    "    add_time_cond=add_time_cond,\n",
    "    filter_beginning_end=False,\n",
    ")\n",
    "ax[1] = plot_background(ax[1], X_train, y_train, t_train, arrows=False)\n",
    "ax[1].set_title(\"Predicted Trajectory FSI\", fontsize=18)\n",
    "# Plot interpolation between one sample per condition, use a natural cubic spline\n",
    "for seed in range(1):\n",
    "    filename = f\"dgp_waves_{DGP}_{seed}_{ns_per_t_and_c}_{train_test_split}_{off_diagonal}_{data_std}_{dimension}\"\n",
    "    if add_time_cond:\n",
    "        filename = filename + \"_\" + re.sub(r\"[(), ]\", \"\", str(add_time_cond))\n",
    "    results_path = Path(path_name_fsi) / filename\n",
    "\n",
    "    if coupling == \"ot\":\n",
    "        name = \"model_ot_fsi.pkl\"\n",
    "    elif coupling == \"cot\":\n",
    "        name = \"model_cot_fsi.pkl\"\n",
    "    elif coupling == \"None\":\n",
    "        name = \"model_fsi.pkl\"\n",
    "    else:\n",
    "        raise ValueError(\"Coupling not recognized.\")\n",
    "\n",
    "    with open(results_path / name, \"rb\") as f:\n",
    "        fsi_model = cloudpickle.load(f)\n",
    "\n",
    "    # Plot trajectory\n",
    "    for idx_c, condition in enumerate([2, 3, 5, 6.5]):\n",
    "        color_conditions = list(label_list).index(condition)\n",
    "        T = 100\n",
    "        trajectory = np.nan * np.ones(shape=(T + 1, 10, 2))\n",
    "        for idx, sample in enumerate(range(5)):\n",
    "            sample_c = np.where(y_test[:, 0] == condition)[0]\n",
    "            for tx in range(T + 1):\n",
    "                transport_c = fsi_model.interpolate_from_x0(\n",
    "                    # X=X_test[sample_c[sample], 0][None, :],\n",
    "                    X=x_means[sample_c[sample]][None, :],\n",
    "                    y=condition,\n",
    "                    t_query=tx / T,\n",
    "                )\n",
    "                trajectory[tx, idx] = transport_c\n",
    "\n",
    "        for sample in range(3):\n",
    "            for t in range(T):\n",
    "                ax[1].plot(\n",
    "                    [trajectory[t, sample, 0], trajectory[t + 1, sample, 0]],\n",
    "                    [trajectory[t, sample, 1], trajectory[t + 1, sample, 1]],\n",
    "                    color=COLORMAP12[color_conditions],\n",
    "                    lw=3,\n",
    "                )\n",
    "\n",
    "#\n",
    "# Figure 3 shows MMFM Predicted Trajectory\n",
    "#\n",
    "add_time_cond = None\n",
    "train_loader, X_train, y_train, t_train, X_valid, y_valid, t_valid, n_classes, label_list = dgp_waves_data(\n",
    "    coupling,\n",
    "    batch_size,\n",
    "    dimension,\n",
    "    off_diagonal,\n",
    "    data_std,\n",
    "    ns_per_t_and_c,\n",
    "    dgp=DGP,\n",
    "    return_data=\"train-valid\",\n",
    "    add_time_cond=add_time_cond,\n",
    "    filter_beginning_end=False,\n",
    ")\n",
    "ax[2] = plot_background(ax[2], X_train, y_train, t_train, arrows=False, legend=True)\n",
    "ax[2].set_title(\"Predicted Trajectory COT-MMFM\", fontsize=18)\n",
    "\n",
    "# Plot interpolation between one sample per condition, use a natural cubic spline\n",
    "for seed in range(1):\n",
    "    for idx, condition in enumerate([2, 3, 5, 6.5]):\n",
    "        color_conditions = list(label_list).index(condition)\n",
    "        sub_trajectories = trajectories_test_mmfm[condition][1][\n",
    "            :, ((color_conditions) * 50) : ((color_conditions + 1) * 50)\n",
    "        ]\n",
    "        for sample in range(3):\n",
    "            for t in range(T):\n",
    "                # Connect two coordinates by line\n",
    "                ax[2].plot(\n",
    "                    [sub_trajectories[t, sample, 0], sub_trajectories[t + 1, sample, 0]],\n",
    "                    [sub_trajectories[t, sample, 1], sub_trajectories[t + 1, sample, 1]],\n",
    "                    color=COLORMAP12[color_conditions],\n",
    "                    lw=3,\n",
    "                )\n",
    "\n",
    "# Create a single legend for the figure\n",
    "handles, labels = fig.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(\n",
    "    by_label.values(),\n",
    "    by_label.keys(),\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(0.86, 0.5),\n",
    "    handler_map={plt.Line2D: ThickerLine2D()},\n",
    ")\n",
    "\n",
    "for k in range(3):\n",
    "    ax[k].set_xlabel(\"x\")\n",
    "    ax[k].set_ylabel(\"y\")\n",
    "\n",
    "# Remove legend from third subplot\n",
    "ax[2].get_legend().remove()\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(right=0.85)\n",
    "# Add dots at integer coordinates\n",
    "for a in ax.flatten():\n",
    "    x_dots = np.linspace(-0.1, 3.1, 23)\n",
    "    y_dots = np.linspace(-0.3, 4.3, 24)\n",
    "    for x in x_dots:\n",
    "        for y in y_dots:\n",
    "            a.scatter(x, y, color=\"gray\", s=2, alpha=0.5, marker=\"+\")\n",
    "\n",
    "# Incease x ticks labels and axis labels\n",
    "for a in ax:\n",
    "    a.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "    a.set_xlabel(a.get_xlabel(), fontsize=16)\n",
    "    a.set_ylabel(a.get_ylabel(), fontsize=16)\n",
    "\n",
    "# Save figure as png\n",
    "plt.savefig(\"/home/rohbeckm/code/mmfm/figures_paper/gt_fsi_mmfm_35.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results to disk\n",
    "load_results = False\n",
    "save_results = True\n",
    "\n",
    "if load_results:\n",
    "    df_cubic_results_mmfm = pd.read_csv(\"final_df_cubic_results_mmfm.csv\")\n",
    "\n",
    "if save_results:\n",
    "    df_cubic_results_mmfm.to_csv(\"final_df_cubic_results_mmfm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark vs Competitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_testset_fsi(\n",
    "    results_path,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    t_test,\n",
    "    seed,\n",
    "    coupling,\n",
    "    plot_results,\n",
    "    ncols,\n",
    "    verbose=False,\n",
    "    n_classes=None,\n",
    "):\n",
    "    df_results_fsi = pd.DataFrame()\n",
    "    results = []\n",
    "\n",
    "    if coupling == \"ot\":\n",
    "        name = \"model_ot_fsi.pkl\"\n",
    "    elif coupling == \"cot\":\n",
    "        name = \"model_cot_fsi.pkl\"\n",
    "    elif coupling == \"None\":\n",
    "        name = \"model_fsi.pkl\"\n",
    "    else:\n",
    "        raise ValueError(\"Coupling not recognized.\")\n",
    "\n",
    "    with open(results_path / name, \"rb\") as f:\n",
    "        if verbose:\n",
    "            print(f\"Loading {name}\")\n",
    "        fsi_model = cloudpickle.load(f)\n",
    "\n",
    "    for marginal, time in enumerate(np.unique(t_test)):\n",
    "        for c in [x for x in np.unique(y_test) if np.isfinite(x)]:  # FIXME: Is this filtering correct?\n",
    "            target = X_test[:, marginal][y_test[:, marginal] == c]\n",
    "            transport = fsi_model.interpolate_from_x0(\n",
    "                X=X_test[:, 0][y_test[:, 0] == c],\n",
    "                y=c if coupling == \"cot\" else None,\n",
    "                t_query=float(time),  # FIXME: This must always be float or int?\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                mmd, mmd_median, wasserstein, mean_diff_l1, mean_diff_l2, kl_div = compute_metric_set(target, transport)\n",
    "            except ValueError:\n",
    "                mmd, mmd_median, wasserstein, mean_diff_l1, mean_diff_l2, kl_div = [np.nan] * 6\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"seed\": seed,\n",
    "                    \"model\": \"FSI\" if coupling == \"None\" else f\"{coupling.upper()}-FSI\",  # FIXME: Is this \"NONE\"?\n",
    "                    \"marginal\": marginal,\n",
    "                    \"c\": c,\n",
    "                    \"mmd\": mmd,\n",
    "                    \"mmd_median\": mmd_median,\n",
    "                    \"wasserstein\": wasserstein,\n",
    "                    \"mean_diff_l1\": mean_diff_l1,\n",
    "                    \"mean_diff_l2\": mean_diff_l2,\n",
    "                    \"kl_div\": kl_div,\n",
    "                    \"time\": time,\n",
    "                }\n",
    "            )\n",
    "    df_results_fsi = pd.DataFrame(results)\n",
    "\n",
    "    if plot_results:\n",
    "        idx_plot = []\n",
    "        for c in np.unique(y_test[:, 0]):\n",
    "            idx = np.where(y_test[:, 0] == c)[0][:1]\n",
    "            idx_plot.append(idx)\n",
    "        idx_plot = [x.item() for x in np.array(idx_plot).flatten()]\n",
    "        \n",
    "        fsi_model.plot_interpolation_beijing(\n",
    "            X_test,\n",
    "            y_test,\n",
    "            t_test,\n",
    "            n_classes=n_classes if n_classes is not None else 9,\n",
    "            idx_plot=idx_plot,\n",
    "            title=None,\n",
    "            save=True,\n",
    "            filename=\"fsi\",\n",
    "            filepath=\"../../figures_paper/\",\n",
    "            coupling=coupling,\n",
    "            s=5,\n",
    "            ncols=ncols,\n",
    "            plot_ode=None,\n",
    "        )\n",
    "\n",
    "    return df_results_fsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, t_test, n_classes, timepoints, all_classes = dgp_beijing_data(\n",
    "    coupling, batch_size, ns_per_t_and_c, dgp=DGP, return_data=\"test\"\n",
    ")\n",
    "\n",
    "# Evaluate FSI models on the same TEST data\n",
    "df_cubic_results_fsi = []\n",
    "add_time_cond = None  #[(i, 0.15) for i in label_list]  # This is the holdout timepoint, FSI is allowed to use\n",
    "for seed in range(1):\n",
    "    filename = f\"dgp_weather_{DGP}_{seed}_{ns_per_t_and_c}_{train_test_split}\"\n",
    "    if add_time_cond is not None:\n",
    "        filename = filename + \"_\" + re.sub(r\"[(), ]\", \"\", str(add_time_cond))\n",
    "    results_path = Path(path_name_fsi) / filename\n",
    "\n",
    "    df_results_fsi = predict_on_testset_fsi(\n",
    "        results_path,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        t_test,\n",
    "        seed=seed,\n",
    "        coupling=coupling,\n",
    "        n_classes=len(label_list),\n",
    "        plot_results=True if seed == 0 else False,\n",
    "        ncols=6,\n",
    "    )\n",
    "    df_cubic_results_fsi.append(df_results_fsi)\n",
    "\n",
    "df_cubic_results_fsi = pd.concat(df_cubic_results_fsi).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to disk\n",
    "load_results = False\n",
    "save_results = True\n",
    "\n",
    "if load_results:\n",
    "    df_cubic_results_fsi = pd.read_csv(\"final_df_cubic_results_fsi.csv\")\n",
    "\n",
    "if save_results:\n",
    "    df_cubic_results_fsi.to_csv(\"final_df_cubic_results_fsi.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, grouping_columns, performance_columns = load_all_models(\n",
    "    PROD, DGP, load_parquet=True, coupling=coupling, embedding_type=embedding_type, filter_values=\"_fm\"\n",
    ")\n",
    "model_type = \"fm\"\n",
    "\n",
    "print(f\"Data before filtering: {df.shape}\")\n",
    "\n",
    "df = df.loc[\n",
    "    (df[\"ns_per_t_and_c\"] == ns_per_t_and_c)\n",
    "    & (df[\"coupling\"] == coupling)\n",
    "    & (df[\"data_std\"] == data_std)\n",
    "    & (df[\"off_diagonal\"] == off_diagonal)\n",
    "    & (df[\"train_test_split\"] == train_test_split)\n",
    "    & (df[\"model_type\"] == model_type)\n",
    "]\n",
    "if not classifier_free:\n",
    "    df = df.loc[~df[\"classifier_free\"]]\n",
    "\n",
    "# Filter for validation results\n",
    "df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "df = df.loc[~df[\"train\"]]\n",
    "\n",
    "print(f\"Data after 1st filtering: {df.shape}\")\n",
    "\n",
    "df, grouping_columns, performance_columns = process_all_fm_models(\n",
    "    df,\n",
    "    grouping_columns,\n",
    "    performance_columns,\n",
    "    plot=False,\n",
    "    verbose=False,\n",
    "    minimum_seeds=5,\n",
    "    data_cols=[\n",
    "        \"ns_per_t_and_c\",\n",
    "        \"coupling\",\n",
    "        \"data_std\",\n",
    "        \"dgp\",\n",
    "        \"interpolation\",\n",
    "        \"guidance\",\n",
    "        \"embedding_type\",\n",
    "        \"classifier_free\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_cubic = df.loc[(df[\"interpolation\"] == \"cubic\")]\n",
    "\n",
    "print(f\"Data after 2nd filtering: {df_cubic.shape}\")\n",
    "\n",
    "\n",
    "df_cubic = df_cubic.copy()\n",
    "df_cubic.loc[:, \"weight\"] = 1\n",
    "\n",
    "df_cubic_valid = df_cubic.loc[(df_cubic[\"time\"].isin([0, 1.0]))]\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"] == 0.15), \"weight\"] = 10\n",
    "\n",
    "model_battery, model_guidances, model_states = get_model_battery_of_best_models_wc(\n",
    "    df_cubic_valid, select_by, n_top_seeds, model_string, DGP, average_out_seed=True, selector=\"mean\"\n",
    ")\n",
    "\n",
    "X_test, y_test, t_test, n_classes, timepoints, all_classes = dgp_waves_data(\n",
    "    coupling, batch_size, dimension, off_diagonal, data_std, ns_per_t_and_c, dgp=DGP, return_data=\"test\"\n",
    ")\n",
    "\n",
    "results_fm = Dict()\n",
    "trajectories_test_fm = Dict()\n",
    "\n",
    "for seed, model in model_battery.items():\n",
    "    results = []\n",
    "    for idx, c in enumerate(label_list):\n",
    "        trajectories_test_fm[c][seed] = sample_trajectory(\n",
    "            model,\n",
    "            X=x_means,\n",
    "            y=y_test[:, 0],\n",
    "            device=device,\n",
    "            guidance=model_guidances[c],\n",
    "            conditional_model=model_states[seed][\"conditional_model\"],\n",
    "            rtol=1e-7,\n",
    "            atol=1e-9,\n",
    "            steps=101,\n",
    "            method=\"rk4\",\n",
    "        )\n",
    "\n",
    "        trajectory = np.swapaxes(trajectories_test_fm[c][seed], 0, 1)\n",
    "        trajectory = trajectory[\n",
    "            np.arange(trajectory.shape[0])[:, None], (t_test * (trajectory.shape[1] - 1)).astype(int)\n",
    "        ]\n",
    "\n",
    "        for marginal in range(trajectory.shape[1]):\n",
    "            target = X_test[:, marginal][y_test[:, marginal] == c]\n",
    "            transport = trajectory[:, marginal][y_test[:, 0] == c]\n",
    "            mmd, mmd_median, wasserstein, mean_diff_l1, mean_diff_l2, kl_div = compute_metric_set(target, transport)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"marginal\": marginal,\n",
    "                    \"c\": c,\n",
    "                    \"mmd\": mmd,\n",
    "                    \"mmd_median\": mmd_median,\n",
    "                    \"wasserstein\": wasserstein,\n",
    "                    \"guidance\": model_guidances[c],\n",
    "                    \"train\": False,\n",
    "                    \"time\": t_test[0, marginal],\n",
    "                    \"mean_diff_l1\": mean_diff_l1,\n",
    "                    \"mean_diff_l2\": mean_diff_l2,\n",
    "                    \"kl_div\": kl_div,\n",
    "                    \"seed\": seed,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_fm[seed] = pd.DataFrame(results)\n",
    "\n",
    "df_cubic_results_fm = pd.concat([results_fm[seed] for seed in results_fm], axis=0)\n",
    "df_cubic_results_fm[\"model\"] = \"OT-CFM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to disk\n",
    "load_results = False\n",
    "save_results = True\n",
    "\n",
    "if load_results:\n",
    "    df_cubic_results_fm = pd.read_csv(\"final_df_cubic_results_fm.csv\")\n",
    "\n",
    "if save_results:\n",
    "    df_cubic_results_fm.to_csv(\"final_df_cubic_results_fm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear COT-MMFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, grouping_columns, performance_columns = load_all_models(\n",
    "    PROD, DGP, load_parquet=True, coupling=coupling, embedding_type=embedding_type, filter_values=\"_mmfm\"\n",
    ")\n",
    "model_type = \"mmfm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data before filtering: {df.shape}\")\n",
    "\n",
    "df = df.loc[\n",
    "    (df[\"ns_per_t_and_c\"] == ns_per_t_and_c)\n",
    "    & (df[\"coupling\"] == coupling)\n",
    "    & (df[\"data_std\"] == data_std)\n",
    "    & (df[\"off_diagonal\"] == off_diagonal)\n",
    "    & (df[\"train_test_split\"] == train_test_split)\n",
    "    & (df[\"model_type\"] == model_type)\n",
    "]\n",
    "if not classifier_free:\n",
    "    df = df.loc[~df[\"classifier_free\"]]\n",
    "\n",
    "# Filter for validation results\n",
    "df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "df = df.loc[~df[\"train\"]]\n",
    "\n",
    "print(f\"Data after 1st filtering: {df.shape}\")\n",
    "\n",
    "df, grouping_columns, performance_columns = process_all_fm_models(\n",
    "    df,\n",
    "    grouping_columns,\n",
    "    performance_columns,\n",
    "    plot=False,\n",
    "    verbose=False,\n",
    "    minimum_seeds=5,\n",
    "    data_cols=[\n",
    "        \"ns_per_t_and_c\",\n",
    "        \"coupling\",\n",
    "        \"data_std\",\n",
    "        \"dgp\",\n",
    "        \"interpolation\",\n",
    "        \"guidance\",\n",
    "        \"embedding_type\",\n",
    "        \"classifier_free\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_cubic = df.loc[(df[\"interpolation\"] == \"linear\")]\n",
    "\n",
    "print(f\"Data after 2nd filtering: {df_cubic.shape}\")\n",
    "\n",
    "df_cubic = df_cubic.copy()\n",
    "df_cubic.loc[:, \"weight\"] = 1\n",
    "\n",
    "df_cubic_valid = df_cubic.loc[\n",
    "    ((df_cubic[\"c\"] == 3) & (df_cubic[\"time\"].isin([0, 0.1, 0.15, 0.5, 0.9, 1.0])))\n",
    "    | ((df_cubic[\"c\"] == 5) & (df_cubic[\"time\"].isin([0, 0.15, 0.3, 0.5, 0.7, 1.0])))\n",
    "    | ((df_cubic[\"c\"] != 3) & (df_cubic[\"c\"] != 5) & (df_cubic[\"time\"].isin([0, 0.1, 0.15, 0.3, 0.5, 0.7, 0.9, 1.0])))\n",
    "]\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"] == 0.15), \"weight\"] = 10\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"].isin([1])), \"weight\"] = 5\n",
    "\n",
    "model_battery, model_guidances, model_states = get_model_battery_of_best_models_wc(\n",
    "    df_cubic_valid, select_by, n_top_seeds, model_string, DGP, average_out_seed=True, selector=\"mean\"\n",
    ")\n",
    "\n",
    "X_test, y_test, t_test, n_classes, timepoints, all_classes = dgp_waves_data(\n",
    "    coupling, batch_size, dimension, off_diagonal, data_std, ns_per_t_and_c, dgp=DGP, return_data=\"test\"\n",
    ")\n",
    "\n",
    "results_mmfmlin = Dict()\n",
    "trajectories_test_mmfmlin = Dict()\n",
    "\n",
    "for seed, model in model_battery.items():\n",
    "    results = []\n",
    "    for idx, c in enumerate(label_list):\n",
    "        trajectories_test_mmfmlin[c][seed] = sample_trajectory(\n",
    "            model,\n",
    "            X=x_means,\n",
    "            y=y_test[:, 0],\n",
    "            device=device,\n",
    "            guidance=model_guidances[c],\n",
    "            conditional_model=model_states[seed][\"conditional_model\"],\n",
    "            rtol=1e-7,\n",
    "            atol=1e-9,\n",
    "            steps=101,\n",
    "            method=\"rk4\",\n",
    "        )\n",
    "\n",
    "        trajectory = np.swapaxes(trajectories_test_mmfmlin[c][seed], 0, 1)\n",
    "        trajectory = trajectory[\n",
    "            np.arange(trajectory.shape[0])[:, None], (t_test * (trajectory.shape[1] - 1)).astype(int)\n",
    "        ]\n",
    "\n",
    "        for marginal in range(trajectory.shape[1]):\n",
    "            target = X_test[:, marginal][y_test[:, marginal] == c]\n",
    "            transport = trajectory[:, marginal][y_test[:, 0] == c]\n",
    "            mmd, mmd_median, wasserstein, mean_diff_l1, mean_diff_l2, kl_div = compute_metric_set(target, transport)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"marginal\": marginal,\n",
    "                    \"c\": c,\n",
    "                    \"mmd\": mmd,\n",
    "                    \"mmd_median\": mmd_median,\n",
    "                    \"wasserstein\": wasserstein,\n",
    "                    \"guidance\": model_guidances[c],\n",
    "                    \"train\": False,\n",
    "                    \"time\": t_test[0, marginal],\n",
    "                    \"mean_diff_l1\": mean_diff_l1,\n",
    "                    \"mean_diff_l2\": mean_diff_l2,\n",
    "                    \"kl_div\": kl_div,\n",
    "                    \"seed\": seed,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_mmfmlin[seed] = pd.DataFrame(results)\n",
    "\n",
    "df_cubic_results_mmfmlin = pd.concat([results_mmfmlin[seed] for seed in results_mmfmlin], axis=0)\n",
    "df_cubic_results_mmfmlin[\"model\"] = \"L-COT-MMFM\"\n",
    "\n",
    "for seed in range(1):\n",
    "    try:\n",
    "        plot_models_wc(\n",
    "            trajectories_test_mmfmlin,\n",
    "            6,\n",
    "            20,\n",
    "            coupling,\n",
    "            batch_size,\n",
    "            dimension,\n",
    "            off_diagonal,\n",
    "            data_std,\n",
    "            ns_per_t_and_c,\n",
    "            DGP,\n",
    "            seed,\n",
    "            save=True,\n",
    "            suffix=\"L-COT-MMFM\",\n",
    "        )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to disk\n",
    "load_results = False\n",
    "save_results = True\n",
    "\n",
    "if load_results:\n",
    "    df_cubic_results_mmfmlin = pd.read_csv(\"final_df_cubic_results_mmfmlin.csv\")\n",
    "\n",
    "if save_results:\n",
    "    df_cubic_results_mmfmlin.to_csv(\"final_df_cubic_results_mmfmlin.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TC-OT-CFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, grouping_columns, performance_columns = load_all_models(\n",
    "    PROD, DGP, load_parquet=False, coupling=coupling, embedding_type=embedding_type, filter_values=\"_tcotcfm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"tcotcfm\"\n",
    "\n",
    "print(f\"Data before filtering: {df.shape}\")\n",
    "\n",
    "df = df.loc[\n",
    "    (df[\"ns_per_t_and_c\"] == ns_per_t_and_c)\n",
    "    & (df[\"coupling\"] == coupling)\n",
    "    & (df[\"data_std\"] == data_std)\n",
    "    & (df[\"off_diagonal\"] == off_diagonal)\n",
    "    & (df[\"train_test_split\"] == train_test_split)\n",
    "    & (df[\"model_type\"] == model_type)\n",
    "]\n",
    "if not classifier_free:\n",
    "    df = df.loc[~df[\"classifier_free\"]]\n",
    "\n",
    "# Filter for validation results\n",
    "df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "df = df.loc[~df[\"train\"]]\n",
    "\n",
    "print(f\"Data after 1st filtering: {df.shape}\")\n",
    "\n",
    "df, grouping_columns, performance_columns = process_all_fm_models(\n",
    "    df,\n",
    "    grouping_columns,\n",
    "    performance_columns,\n",
    "    plot=False,\n",
    "    verbose=True,\n",
    "    minimum_seeds=5,\n",
    "    data_cols=[\n",
    "        \"ns_per_t_and_c\",\n",
    "        \"coupling\",\n",
    "        \"data_std\",\n",
    "        \"dgp\",\n",
    "        \"interpolation\",\n",
    "        \"guidance\",\n",
    "        \"embedding_type\",\n",
    "        \"classifier_free\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# df_cubic = df.loc[(df[\"interpolation\"] == \"linear\")]\n",
    "\n",
    "print(f\"Data after 2nd filtering: {df.shape}\")\n",
    "\n",
    "df_cubic = df.copy()\n",
    "df_cubic.loc[:, \"weight\"] = 1\n",
    "\n",
    "df_cubic_valid = df_cubic.loc[\n",
    "    ((df_cubic[\"c\"] == 3) & (df_cubic[\"time\"].isin([0, 0.1, 0.15, 0.5, 0.9, 1.0])))\n",
    "    | ((df_cubic[\"c\"] == 5) & (df_cubic[\"time\"].isin([0, 0.15, 0.3, 0.5, 0.7, 1.0])))\n",
    "    | ((df_cubic[\"c\"] != 3) & (df_cubic[\"c\"] != 5) & (df_cubic[\"time\"].isin([0, 0.1, 0.15, 0.3, 0.5, 0.7, 0.9, 1.0])))\n",
    "]\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"] == 0.15), \"weight\"] = 10\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"].isin([1])), \"weight\"] = 5\n",
    "\n",
    "model_battery, model_guidances, model_states = get_model_battery_of_best_models_wc(\n",
    "    df_cubic_valid, select_by, n_top_seeds, model_string, DGP, average_out_seed=True, selector=\"mean\", model=\"tcotcfm\"\n",
    ")\n",
    "\n",
    "X_test, y_test, t_test, n_classes, timepoints, all_classes = dgp_waves_data(\n",
    "    coupling, batch_size, dimension, off_diagonal, data_std, ns_per_t_and_c, dgp=DGP, return_data=\"test\"\n",
    ")\n",
    "\n",
    "results_tcotcfm = Dict()\n",
    "trajectories_test_tcotcfm = Dict()\n",
    "\n",
    "for seed, model in model_battery.items():\n",
    "    results = []\n",
    "    for idx, c in enumerate(label_list):\n",
    "        trajectories_test_tcotcfm[c][seed] = sample_trajectory(\n",
    "            model,\n",
    "            X=x_means[y_test[:, 0] == c, :],\n",
    "            y=y_test[y_test[:, 0] == c, 0],\n",
    "            device=device,\n",
    "            guidance=model_guidances[c],\n",
    "            conditional_model=model_states[seed][\"conditional_model\"],\n",
    "            rtol=1e-7,\n",
    "            atol=1e-9,\n",
    "            steps=101,\n",
    "            method=\"rk4\",\n",
    "        )\n",
    "\n",
    "        trajectory = np.swapaxes(trajectories_test_tcotcfm[c][seed], 0, 1)\n",
    "        trajectory = trajectory[\n",
    "            np.arange(trajectory.shape[0])[:, None],\n",
    "            (t_test[y_test[:, 0] == c, :] * (trajectory.shape[1] - 1)).astype(int),\n",
    "        ]\n",
    "\n",
    "        for marginal in range(trajectory.shape[1]):\n",
    "            target = X_test[:, marginal][y_test[:, marginal] == c]\n",
    "            transport = trajectory[:, marginal]  # [y_test[:, 0] == c]\n",
    "            mmd, mmd_median, wasserstein, mean_diff_l1, mean_diff_l2, kl_div = compute_metric_set(\n",
    "                target, transport, kl_div_skip=True\n",
    "            )\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"marginal\": marginal,\n",
    "                    \"c\": c,\n",
    "                    \"mmd\": mmd,\n",
    "                    \"mmd_median\": mmd_median,\n",
    "                    \"wasserstein\": wasserstein,\n",
    "                    \"guidance\": model_guidances[c],\n",
    "                    \"train\": False,\n",
    "                    \"time\": t_test[0, marginal],\n",
    "                    \"mean_diff_l1\": mean_diff_l1,\n",
    "                    \"mean_diff_l2\": mean_diff_l2,\n",
    "                    \"kl_div\": kl_div,\n",
    "                    \"seed\": seed,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_tcotcfm[seed] = pd.DataFrame(results)\n",
    "\n",
    "df_cubic_results_tcotcfm = pd.concat([results_tcotcfm[seed] for seed in results_tcotcfm], axis=0)\n",
    "df_cubic_results_tcotcfm[\"model\"] = \"TC-OT-CFM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in range(1):\n",
    "    plot_models_wc(\n",
    "        trajectories_test_tcotcfm,\n",
    "        6,\n",
    "        20,\n",
    "        coupling,\n",
    "        batch_size,\n",
    "        dimension,\n",
    "        off_diagonal,\n",
    "        data_std,\n",
    "        ns_per_t_and_c,\n",
    "        DGP,\n",
    "        seed,\n",
    "        save=True,\n",
    "        suffix=\"TC-OT-CFM\",\n",
    "        already_subset=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to disk\n",
    "load_results = False\n",
    "save_results = True\n",
    "\n",
    "if load_results:\n",
    "    df_cubic_results_tcotcfm = pd.read_csv(\"final_df_cubic_results_tcotcfm.csv\")\n",
    "\n",
    "if save_results:\n",
    "    df_cubic_results_tcotcfm.to_csv(\"final_df_cubic_results_tcotcfm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-OT-CFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, grouping_columns, performance_columns = load_all_models(\n",
    "    PROD, DGP, load_parquet=False, coupling=coupling, embedding_type=embedding_type, filter_values=\"totcfm\"\n",
    ")\n",
    "print(f\"Data before filtering: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"totcfm\"\n",
    "\n",
    "df = df.loc[\n",
    "    (df[\"ns_per_t_and_c\"] == ns_per_t_and_c)\n",
    "    & (df[\"coupling\"] == coupling)\n",
    "    & (df[\"data_std\"] == data_std)\n",
    "    & (df[\"off_diagonal\"] == off_diagonal)\n",
    "    & (df[\"train_test_split\"] == train_test_split)\n",
    "    & (df[\"model_type\"] == model_type)\n",
    "]\n",
    "if not classifier_free:\n",
    "    df = df.loc[~df[\"classifier_free\"]]\n",
    "\n",
    "# Filter for validation results\n",
    "df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "df = df.loc[~df[\"train\"]]\n",
    "\n",
    "print(f\"Data after 1st filtering: {df.shape}\")\n",
    "\n",
    "df, grouping_columns, performance_columns = process_all_fm_models(\n",
    "    df,\n",
    "    grouping_columns,\n",
    "    performance_columns,\n",
    "    plot=False,\n",
    "    verbose=True,\n",
    "    minimum_seeds=5,\n",
    "    data_cols=[\n",
    "        \"ns_per_t_and_c\",\n",
    "        \"coupling\",\n",
    "        \"data_std\",\n",
    "        \"dgp\",\n",
    "        \"interpolation\",\n",
    "        \"guidance\",\n",
    "        \"embedding_type\",\n",
    "        \"classifier_free\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Data after 2nd filtering: {df.shape}\")\n",
    "\n",
    "df_cubic = df.copy()\n",
    "df_cubic.loc[:, \"weight\"] = 1\n",
    "\n",
    "df_cubic_valid = df_cubic.loc[\n",
    "    ((df_cubic[\"c\"] == 3) & (df_cubic[\"time\"].isin([0, 0.1, 0.15, 0.5, 0.9, 1.0])))\n",
    "    | ((df_cubic[\"c\"] == 5) & (df_cubic[\"time\"].isin([0, 0.15, 0.3, 0.5, 0.7, 1.0])))\n",
    "    | ((df_cubic[\"c\"] != 3) & (df_cubic[\"c\"] != 5) & (df_cubic[\"time\"].isin([0, 0.1, 0.15, 0.3, 0.5, 0.7, 0.9, 1.0])))\n",
    "]\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"] == 0.15), \"weight\"] = 10\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"].isin([1])), \"weight\"] = 5\n",
    "\n",
    "model_battery, model_guidances, model_states = get_model_battery_of_best_models_wc(\n",
    "    df_cubic_valid, select_by, n_top_seeds, model_string, DGP, average_out_seed=True, selector=\"mean\", model=\"totcfm\"\n",
    ")\n",
    "\n",
    "X_test, y_test, t_test, n_classes, timepoints, all_classes = dgp_waves_data(\n",
    "    coupling, batch_size, dimension, off_diagonal, data_std, ns_per_t_and_c, dgp=DGP, return_data=\"test\"\n",
    ")\n",
    "\n",
    "results_totcfm = Dict()\n",
    "trajectories_test_totcfm = Dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed, model in model_battery.items():\n",
    "    results = []\n",
    "    for idx, c in enumerate(label_list):\n",
    "        trajectories_test_totcfm[c][seed] = sample_trajectory(\n",
    "            model,\n",
    "            X=x_means[y_test[:, 0] == c, :],\n",
    "            y=y_test[y_test[:, 0] == c, 0],\n",
    "            device=device,\n",
    "            guidance=model_guidances[c],\n",
    "            conditional_model=model_states[seed][\"conditional_model\"],\n",
    "            rtol=1e-7,\n",
    "            atol=1e-9,\n",
    "            steps=101,\n",
    "            method=\"rk4\",\n",
    "        )\n",
    "\n",
    "        trajectory = np.swapaxes(trajectories_test_totcfm[c][seed], 0, 1)\n",
    "        trajectory = trajectory[\n",
    "            np.arange(trajectory.shape[0])[:, None],\n",
    "            (t_test[y_test[:, 0] == c, :] * (trajectory.shape[1] - 1)).astype(int),\n",
    "        ]\n",
    "\n",
    "        for marginal in range(trajectory.shape[1]):\n",
    "            target = X_test[:, marginal][y_test[:, marginal] == c]\n",
    "            transport = trajectory[:, marginal]  # [y_test[:, 0] == c]\n",
    "            mmd, mmd_median, wasserstein, mean_diff_l1, mean_diff_l2, kl_div = compute_metric_set(\n",
    "                target, transport, kl_div_skip=True\n",
    "            )\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"marginal\": marginal,\n",
    "                    \"c\": c,\n",
    "                    \"mmd\": mmd,\n",
    "                    \"mmd_median\": mmd_median,\n",
    "                    \"wasserstein\": wasserstein,\n",
    "                    \"guidance\": model_guidances[c],\n",
    "                    \"train\": False,\n",
    "                    \"time\": t_test[0, marginal],\n",
    "                    \"mean_diff_l1\": mean_diff_l1,\n",
    "                    \"mean_diff_l2\": mean_diff_l2,\n",
    "                    \"kl_div\": kl_div,\n",
    "                    \"seed\": seed,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_totcfm[seed] = pd.DataFrame(results)\n",
    "\n",
    "df_cubic_results_totcfm = pd.concat([results_totcfm[seed] for seed in results_totcfm], axis=0)\n",
    "df_cubic_results_totcfm[\"model\"] = \"T-OT-CFM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in range(1):\n",
    "    plot_models_wc(\n",
    "        trajectories_test_totcfm,\n",
    "        6,\n",
    "        20,\n",
    "        coupling,\n",
    "        batch_size,\n",
    "        dimension,\n",
    "        off_diagonal,\n",
    "        data_std,\n",
    "        ns_per_t_and_c,\n",
    "        DGP,\n",
    "        seed,\n",
    "        save=True,\n",
    "        suffix=\"T-OT-CFM\",\n",
    "        already_subset=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to disk\n",
    "load_results = False\n",
    "save_results = True\n",
    "\n",
    "if load_results:\n",
    "    df_cubic_results_totcfm = pd.read_csv(\"final_df_cubic_results_totcfm.csv\")\n",
    "\n",
    "if save_results:\n",
    "    df_cubic_results_totcfm.to_csv(\"final_df_cubic_results_totcfm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.concat(\n",
    "    [\n",
    "        df_cubic_results_fm,\n",
    "        df_cubic_results_fsi,\n",
    "        df_cubic_results_mmfmlin,\n",
    "        df_cubic_results_mmfm,\n",
    "        df_cubic_results_tcotcfm,\n",
    "        df_cubic_results_totcfm,\n",
    "    ],\n",
    "    ignore_index=True,\n",
    "    axis=0,\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc[:, \"training\"] = False\n",
    "\n",
    "for model_name in [\"COT-MMFM\", \"L-COT-MMFM\", \"T-OT-CFM\", \"L-COT-MMFM\", \"TC-OT-CFM\"]:\n",
    "    df_results.loc[\n",
    "        (df_results[\"c\"] == 3)\n",
    "        & (df_results[\"model\"] == model_name)\n",
    "        & (df_results[\"time\"].isin([0, 0.1, 0.5, 0.9, 1.0])),\n",
    "        \"training\",\n",
    "    ] = True\n",
    "    df_results.loc[\n",
    "        (df_results[\"c\"] == 5)\n",
    "        & (df_results[\"model\"] == model_name)\n",
    "        & (df_results[\"time\"].isin([0, 0.3, 0.5, 0.7, 1.0])),\n",
    "        \"training\",\n",
    "    ] = True\n",
    "    df_results.loc[\n",
    "        (df_results[\"c\"] != 3)\n",
    "        & (df_results[\"c\"] != 5)\n",
    "        & (df_results[\"model\"] == model_name)\n",
    "        & (df_results[\"time\"].isin([0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0])),\n",
    "        \"training\",\n",
    "    ] = True\n",
    "\n",
    "df_results.loc[\n",
    "    (df_results[\"model\"] == \"OT-CFM\") & (df_results[\"time\"].isin([0, 1.0])),\n",
    "    \"training\",\n",
    "] = True\n",
    "\n",
    "df_results.loc[\n",
    "    (df_results[\"c\"] == 3)\n",
    "    & (df_results[\"model\"] == \"COT-FSI\")\n",
    "    & (df_results[\"time\"].isin([0, 0.1, 0.15, 0.5, 0.9, 1.0])),\n",
    "    \"training\",\n",
    "] = True\n",
    "df_results.loc[\n",
    "    (df_results[\"c\"] == 5)\n",
    "    & (df_results[\"model\"] == \"COT-FSI\")\n",
    "    & (df_results[\"time\"].isin([0, 0.15, 0.3, 0.5, 0.7, 1.0])),\n",
    "    \"training\",\n",
    "] = True\n",
    "df_results.loc[\n",
    "    (df_results[\"c\"] != 3)\n",
    "    & (df_results[\"c\"] != 5)\n",
    "    & (df_results[\"model\"] == \"COT-FSI\")\n",
    "    & (df_results[\"time\"].isin([0, 0.1, 0.15, 0.3, 0.5, 0.7, 0.9, 1.0])),\n",
    "    \"training\",\n",
    "] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = (\n",
    "    df_results.groupby([\"model\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"mmd\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mmd_median\": [\"mean\", \"std\", \"max\"],\n",
    "            \"wasserstein\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mean_diff_l1\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mean_diff_l2\": [\"mean\", \"std\", \"max\"],\n",
    "        }\n",
    "    )\n",
    "    .round(2)\n",
    "    .rename(columns={\"model\": \"Model\"})[[\"mean_diff_l2\", \"wasserstein\"]]\n",
    "    .reset_index()\n",
    ")\n",
    "df_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[\"condition_value\"] = df_results[\"c\"].apply(lambda x: \"3\" if x == 3 else (\"5\" if x == 5 else \"R\"))\n",
    "\n",
    "df_r = (\n",
    "    df_results.groupby([\"model\", \"training\", \"condition_value\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"mmd\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mmd_median\": [\"mean\", \"std\", \"max\"],\n",
    "            \"wasserstein\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mean_diff_l1\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mean_diff_l2\": [\"mean\", \"std\", \"max\"],\n",
    "        }\n",
    "    )\n",
    "    .round(2)\n",
    "    .rename(columns={\"model\": \"Model\"})[[\"mean_diff_l1\", \"mean_diff_l2\", \"wasserstein\", \"mmd\", \"mmd_median\"]]\n",
    "    .reset_index()\n",
    ")\n",
    "df_r = df_r.loc[~df_r[\"training\"]]\n",
    "df_r.sort_values([\"condition_value\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
