{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations DGP Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from addict import Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "import cloudpickle\n",
    "\n",
    "from mmfm.data import dgp_waves_data, u\n",
    "from mmfm.mmfm_utils import sample_trajectory\n",
    "from mmfm.evaluation import compute_metric_set\n",
    "from mmfm.models import VectorFieldModel, MultiVectorFieldModel, MultiVectorFieldModelTCFM\n",
    "from mmfm.utils_eval import (\n",
    "    load_all_fm_models,\n",
    "    process_all_fm_models,\n",
    "    predict_on_testset_fsi,\n",
    ")\n",
    "from mmfm.utils import color_picker, create_plot_grid, COLORMAP10, ThickerLine2D, COLORMAP12\n",
    "\n",
    "# Plotting settings\n",
    "params = {\n",
    "    \"axes.labelsize\": 18,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"xtick.labelsize\": 18,\n",
    "    \"ytick.labelsize\": 18,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"legend.title_fontsize\": 18,\n",
    "    \"figure.titlesize\": 30,\n",
    "}\n",
    "plt.rcParams.update(params)\n",
    "plt.style.use([\"science\", \"no-latex\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROD = True\n",
    "minimum_seeds = 5\n",
    "dimension = 2\n",
    "batch_size = None\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "path_name_fsi = \"/home/rohbeckm/scratch/results/dgp_waves/results_fsi\"\n",
    "verbose = False\n",
    "\n",
    "# Data\n",
    "DGP = \"i\"\n",
    "label_list = list(np.linspace(1, 6.5, 12))\n",
    "\n",
    "ns_per_t_and_c = 50\n",
    "coupling = \"cot\"\n",
    "data_std = 0.025\n",
    "off_diagonal = 0.0\n",
    "train_test_split = 0.5\n",
    "embedding_type = \"free\"\n",
    "classifier_free = False\n",
    "\n",
    "n_top_models = 1\n",
    "n_top_seeds = 3\n",
    "model_string = \"dgp_waves\"\n",
    "average_out_seed = False\n",
    "select_by = \"mean_diff_l2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_models(prod, dgp, load_parquet=True, coupling=None, embedding_type=None, filter_values=None):\n",
    "    if load_parquet & (Path(\"data\") / f\"df_gt_{dgp}.parquet\").exists():\n",
    "        # This file contains all model train and validation results in a tidy format\n",
    "        # i.e., each row corresponds to a single model run (model, seed, guidance, etc.)\n",
    "        df = pd.read_parquet(Path(\"data\") / f\"df_gt_{dgp}.parquet\")\n",
    "        # Try to convert each value in column flow_variance to float if possible, otherwise leave value as string\n",
    "        try:\n",
    "            df[\"flow_variance\"] = df[\"flow_variance\"].astype(float)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        with open(Path(\"data\") / f\"grouping_columns_{dgp}.pkl\", \"rb\") as f:\n",
    "            grouping_columns = pickle.load(f)\n",
    "        with open(Path(\"data\") / f\"performance_columns_{dgp}.pkl\", \"rb\") as f:\n",
    "            performance_columns = pickle.load(f)\n",
    "    else:\n",
    "        df, grouping_columns, performance_columns = load_all_fm_models(\n",
    "            path=\"/home/rohbeckm/scratch/results/dgp_waves/results_mmfm\",\n",
    "            production=prod,  # If prod is false, only load a small subset of data\n",
    "            dgp=DGP,\n",
    "            coupling=coupling,\n",
    "            embedding_type=embedding_type,\n",
    "            filter_values=filter_values,\n",
    "        )\n",
    "\n",
    "        # Filter for only validation results\n",
    "        df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "        df = df.loc[~df[\"train\"]]\n",
    "\n",
    "        # Save everything\n",
    "        # Convert\n",
    "        df[\"flow_variance\"] = df[\"flow_variance\"].astype(str)\n",
    "        print(f\"Saving data with shape {df.shape}\")\n",
    "        df.to_parquet(Path(\"data\") / f\"df_gt_{dgp}.parquet\")\n",
    "        # Try to convert each value in column flow_variance to float if possible, otherwise leave value as string\n",
    "        try:\n",
    "            df[\"flow_variance\"] = df[\"flow_variance\"].astype(float)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        with open(Path(\"data\") / f\"grouping_columns_{dgp}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(grouping_columns, f)\n",
    "        with open(Path(\"data\") / f\"performance_columns_{dgp}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(performance_columns, f)\n",
    "\n",
    "    return df, grouping_columns, performance_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess all MMFM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, grouping_columns, performance_columns = load_all_models(\n",
    "    PROD, DGP, load_parquet=False, coupling=coupling, embedding_type=embedding_type, filter_values=\"mmfm\"\n",
    ")\n",
    "model_type = \"mmfm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data before filtering: {df.shape}\")\n",
    "\n",
    "df = df.loc[\n",
    "    (df[\"ns_per_t_and_c\"] == ns_per_t_and_c)\n",
    "    & (df[\"coupling\"] == coupling)\n",
    "    & (df[\"data_std\"] == data_std)\n",
    "    & (df[\"off_diagonal\"] == off_diagonal)\n",
    "    & (df[\"train_test_split\"] == train_test_split)\n",
    "    & (df[\"embedding_type\"] == embedding_type)\n",
    "    & (df[\"model_type\"] == model_type)\n",
    "]\n",
    "if not classifier_free:\n",
    "    df = df.loc[~df[\"classifier_free\"]]\n",
    "\n",
    "# Filter for only validation results\n",
    "df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "df = df.loc[~df[\"train\"]]\n",
    "\n",
    "df = df.loc[(df[\"interpolation\"] == \"cubic\")]\n",
    "\n",
    "print(f\"Data after 1st filtering: {df.shape}\")\n",
    "\n",
    "df, grouping_columns, performance_columns = process_all_fm_models(\n",
    "    df,\n",
    "    grouping_columns,\n",
    "    performance_columns,\n",
    "    plot=False,\n",
    "    verbose=True,\n",
    "    minimum_seeds=minimum_seeds,\n",
    "    data_cols=[\n",
    "        \"ns_per_t_and_c\",\n",
    "        \"coupling\",\n",
    "        \"data_std\",\n",
    "        \"dgp\",\n",
    "        \"interpolation\",\n",
    "        \"guidance\",\n",
    "        \"embedding_type\",\n",
    "        \"classifier_free\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Data after 2nd filtering: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best model on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_battery_of_best_models_wc(\n",
    "    df, select_by, n_top_seeds, model_string, dgp, average_out_seed=True, verbose=False, selector=\"mean\", model=None\n",
    "):\n",
    "    \"\"\"Find best model according to a given metric and return the model battery of the best model.\n",
    "\n",
    "    We use either use mean or max statistics on the holdout validation data to select the best model.\n",
    "    \"\"\"\n",
    "\n",
    "    def weighted_avg(group_df, whole_df, values, weights):\n",
    "        v = whole_df.loc[group_df.index, values]\n",
    "        w = whole_df.loc[group_df.index, weights]\n",
    "        return (v * w).sum() / w.sum()\n",
    "\n",
    "    def weighted_max(group_df, whole_df, values, weights):\n",
    "        v = whole_df.loc[group_df.index, values]\n",
    "        w = whole_df.loc[group_df.index, weights]\n",
    "        return (v * w).max()\n",
    "\n",
    "    if average_out_seed:\n",
    "        grouping = [x for x in grouping_columns if x not in [\"marginal\", \"time\", \"seed\"]]\n",
    "    else:\n",
    "        grouping = [x for x in grouping_columns if x not in [\"marginal\", \"time\"]]\n",
    "\n",
    "    df_agg = (\n",
    "        (\n",
    "            df.drop(columns=[\"marginal\", \"time\"])\n",
    "            .groupby(grouping)\n",
    "            .agg(\n",
    "                scoring_mean=(select_by, lambda x: weighted_avg(x, df, select_by, \"weight\")),\n",
    "                scoring_max=(select_by, lambda x: weighted_max(x, df, select_by, \"weight\")),\n",
    "                filename_first=(\"filename\", \"first\"),\n",
    "            )\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"scoring_mean\": f\"{select_by}_mean\",\n",
    "                \"scoring_max\": f\"{select_by}_max\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Enumerate all filenames\n",
    "    map_filename_to_id = {filename: idx for idx, filename in enumerate(df_agg[\"filename_first\"].unique())}\n",
    "    df_agg[\"id\"] = df_agg[\"filename_first\"].map(map_filename_to_id)\n",
    "\n",
    "    # Average out everything except for id, c, guidance\n",
    "    df_agg2 = df_agg.groupby([\"id\", \"c\", \"guidance\"])[f\"{select_by}_{selector}\"].mean().reset_index()\n",
    "\n",
    "    # For each combination of c and id, find the guidance value where the mean_diff_l2_mean is lowest\n",
    "    guidances = df_agg2.loc[df_agg2.groupby([\"id\", \"c\"])[f\"{select_by}_{selector}\"].idxmin()]\n",
    "\n",
    "    # Compute best score across conditions for each model\n",
    "    guidances_scores = (\n",
    "        guidances.groupby([\"id\"])[f\"{select_by}_{selector}\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .sort_values(by=f\"{select_by}_{selector}\", ascending=True)\n",
    "    )\n",
    "\n",
    "    best_model_id = guidances_scores[\"id\"].iloc[0]\n",
    "    best_model = [x for x in df_agg[\"filename_first\"].unique() if map_filename_to_id[x] == best_model_id][0]\n",
    "\n",
    "    df_agg_c = df.loc[df[\"filename\"] == best_model, :]\n",
    "\n",
    "    model_battery = Dict()\n",
    "    model_guidances = Dict()\n",
    "    model_states = Dict()\n",
    "    gudiance_best_model = guidances[guidances.id == best_model_id]\n",
    "\n",
    "    for _, c in enumerate(df_agg_c[\"c\"].unique()):\n",
    "        model_guidances[c] = gudiance_best_model.loc[gudiance_best_model[\"c\"] == c, \"guidance\"].iloc[0]\n",
    "\n",
    "        # Load the model from its filename and all its seed-variations\n",
    "        model_path = best_model\n",
    "        model_path = model_path.replace(\"df_results.csv\", \"model.pt\")\n",
    "\n",
    "        # print(f\"Loading model from {model_path}\")\n",
    "\n",
    "        for seed in range(n_top_seeds):\n",
    "            # Replace \"dgp2_{seed}\" with \"dgp2_x\" in the path\n",
    "            current_seed = model_path.split(\"_\")[5]\n",
    "            model_path = model_path.replace(f\"{model_string}_{dgp}_{current_seed}\", f\"{model_string}_{dgp}_{seed}\")\n",
    "            filename = model_path.split(\"/\")[-2]\n",
    "\n",
    "            try:\n",
    "                state = torch.load(model_path, weights_only=True)\n",
    "                if verbose:\n",
    "                    print(f\"✓ {filename}\")\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                if verbose:\n",
    "                    print(f\"✗ {filename}\")\n",
    "                continue\n",
    "\n",
    "            if model is None:\n",
    "                mmfm_model = VectorFieldModel(\n",
    "                    data_dim=state[\"dimension\"] if \"dimension\" in state else state[\"use_pca\"],\n",
    "                    x_latent_dim=state[\"x_latent_dim\"],\n",
    "                    time_embed_dim=state[\"time_embed_dim\"],\n",
    "                    cond_embed_dim=state[\"cond_embed_dim\"],\n",
    "                    conditional_model=state[\"conditional_model\"],\n",
    "                    embedding_type=state[\"embedding_type\"],\n",
    "                    n_classes=state[\"n_classes\"],\n",
    "                    label_list=label_list,\n",
    "                    normalization=state[\"normalization\"],\n",
    "                    activation=state[\"activation\"],\n",
    "                    affine_transform=state[\"affine_transform\"],\n",
    "                    sum_time_embed=state[\"sum_time_embed\"],\n",
    "                    sum_cond_embed=state[\"sum_cond_embed\"],\n",
    "                    max_norm_embedding=state[\"max_norm_embedding\"],\n",
    "                    num_out_layers=state[\"num_out_layers\"],\n",
    "                    spectral_norm=state[\"spectral_norm\"],\n",
    "                    dropout=state[\"dropout\"],\n",
    "                    conditional_bias=state[\"conditional_bias\"],\n",
    "                    keep_constants=state[\"keep_constants\"],\n",
    "                ).to(device)\n",
    "            elif model == \"totcfm\":\n",
    "                mmfm_model = MultiVectorFieldModelTCFM(\n",
    "                    model_list=[0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                    data_dim=state[\"dimension\"],\n",
    "                    x_latent_dim=state[\"x_latent_dim\"],\n",
    "                    time_embed_dim=state[\"time_embed_dim\"],\n",
    "                    cond_embed_dim=state[\"cond_embed_dim\"],\n",
    "                    conditional_model=state[\"conditional_model\"],\n",
    "                    embedding_type=state[\"embedding_type\"],\n",
    "                    n_classes=state[\"n_classes\"],\n",
    "                    label_list=label_list,\n",
    "                    normalization=state[\"normalization\"],\n",
    "                    activation=state[\"activation\"],\n",
    "                    affine_transform=state[\"affine_transform\"],\n",
    "                    sum_time_embed=state[\"sum_time_embed\"],\n",
    "                    sum_cond_embed=state[\"sum_cond_embed\"],\n",
    "                    max_norm_embedding=state[\"max_norm_embedding\"],\n",
    "                    num_out_layers=state[\"num_out_layers\"],\n",
    "                    spectral_norm=state[\"spectral_norm\"],\n",
    "                    dropout=state[\"dropout\"],\n",
    "                    conditional_bias=state[\"conditional_bias\"],\n",
    "                    keep_constants=state[\"keep_constants\"],\n",
    "                ).to(device)\n",
    "            elif model == \"tcotcfm\":\n",
    "                mmfm_model = MultiVectorFieldModel(\n",
    "                    model_list={\n",
    "                        1: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        1.5: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        2: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        2.5: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        3: [0, 0.1, 0.5, 0.9, 1],\n",
    "                        3.5: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        4: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        4.5: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        5: [0, 0.3, 0.5, 0.7, 1],\n",
    "                        5.5: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        6: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                        6.5: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "                    },\n",
    "                    data_dim=state[\"dimension\"],\n",
    "                    x_latent_dim=state[\"x_latent_dim\"],\n",
    "                    time_embed_dim=state[\"time_embed_dim\"],\n",
    "                    cond_embed_dim=state[\"cond_embed_dim\"],\n",
    "                    conditional_model=state[\"conditional_model\"],\n",
    "                    embedding_type=state[\"embedding_type\"],\n",
    "                    n_classes=state[\"n_classes\"],\n",
    "                    label_list=label_list,\n",
    "                    normalization=state[\"normalization\"],\n",
    "                    activation=state[\"activation\"],\n",
    "                    affine_transform=state[\"affine_transform\"],\n",
    "                    sum_time_embed=state[\"sum_time_embed\"],\n",
    "                    sum_cond_embed=state[\"sum_cond_embed\"],\n",
    "                    max_norm_embedding=state[\"max_norm_embedding\"],\n",
    "                    num_out_layers=state[\"num_out_layers\"],\n",
    "                    spectral_norm=state[\"spectral_norm\"],\n",
    "                    dropout=state[\"dropout\"],\n",
    "                    conditional_bias=state[\"conditional_bias\"],\n",
    "                    keep_constants=state[\"keep_constants\"],\n",
    "                ).to(device)\n",
    "\n",
    "            mmfm_model.load_state_dict(state[\"state_dict\"], strict=True)\n",
    "            model_battery[seed] = mmfm_model\n",
    "            model_states[seed] = state\n",
    "\n",
    "    return model_battery, model_guidances, model_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_models_wc(\n",
    "    trajectory,\n",
    "    ncols,\n",
    "    s,\n",
    "    coupling,\n",
    "    batch_size,\n",
    "    dimension,\n",
    "    off_diagonal,\n",
    "    data_std,\n",
    "    ns_per_t_and_c,\n",
    "    dgp,\n",
    "    seed=0,\n",
    "    save=False,\n",
    "    suffix=None,\n",
    "    already_subset=False\n",
    "):\n",
    "    \"\"\"Plot the trajectories of the best models for each condition c in a grid.\"\"\"\n",
    "    # We only load the train data, because we want to plot it in the background\n",
    "    _, X_train, y_train, t_train, _, _, _, n_classes, _ = dgp_waves_data(\n",
    "        coupling, batch_size, dimension, off_diagonal, data_std, ns_per_t_and_c, dgp=dgp, return_data=\"train-valid\"\n",
    "    )\n",
    "    t = t_train\n",
    "\n",
    "    fig, ax, ncols, _ = create_plot_grid(n_classes, ncols=ncols)\n",
    "\n",
    "    df = pd.DataFrame(X_train.reshape(-1, 2)).assign(target=y_train.reshape(-1, 1))\n",
    "    df.columns = [\"x\", \"y\", \"target\"]\n",
    "\n",
    "    color_classes = [int(x) for x in range(len([x for x in np.unique(y_train) if np.isfinite(x)]))]\n",
    "    colors = color_picker(color_classes)\n",
    "    non_nan_targets = [x for x in np.unique(y_train) if np.isfinite(x)]\n",
    "\n",
    "    # Plot backgrounds\n",
    "    for k, c in enumerate(non_nan_targets):\n",
    "        axidx = ax[k // ncols, k % ncols]\n",
    "        sns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"target\", ax=axidx, legend=False, alpha=0.05, palette=colors, s=s)\n",
    "        sns.scatterplot(data=df[df[\"target\"] == c], x=\"x\", y=\"y\", ax=axidx, color=colors[k], s=15)\n",
    "        axidx.set_title(f\"Condition c={c}\")\n",
    "\n",
    "    # Plot ground truth trajectories\n",
    "    for k, c in enumerate(non_nan_targets):\n",
    "        if not already_subset:\n",
    "            idx_plot = np.where(y_train[:, 0] == c)[0][:2]\n",
    "        else:\n",
    "            idx_plot = [0, 1]\n",
    "        for n in idx_plot:\n",
    "            y0 = trajectory[c][seed][0, n]#, y_train[n, 0]\n",
    "            t = np.linspace(0, 1, 101)\n",
    "            sol = odeint(u, y0, t, args=(c,))\n",
    "            ax[k // ncols, k % ncols].plot(sol[:, 0], sol[:, 1], color=\"blue\", alpha=0.2, lw=7.5)\n",
    "\n",
    "    # Plot predicted marginals\n",
    "    # Plot ground truth trajectories\n",
    "    for k, c in enumerate(non_nan_targets):\n",
    "        if not already_subset:\n",
    "            idx_plot = np.where(y_train[:, 0] == c)[0][:2]\n",
    "        else:\n",
    "            idx_plot = [0, 1]\n",
    "        for n in idx_plot:\n",
    "            for i in range(len(trajectory[c][seed]) - 1):\n",
    "                ax[k // ncols, k % ncols].plot(\n",
    "                    [trajectory[c][seed][i, n, 0], trajectory[c][seed][i + 1, n, 0]],\n",
    "                    [trajectory[c][seed][i, n, 1], trajectory[c][seed][i + 1, n, 1]],\n",
    "                    color=\"black\",\n",
    "                    lw=2,\n",
    "                )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        fn = f\"/home/rohbeckm/code/mmfm/figures_paper/trajectory_wave_{seed}_35.png\"\n",
    "        if suffix is not None:\n",
    "            fn = fn.replace(\".png\", f\"_{suffix}.png\")\n",
    "        plt.savefig(fn)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weight column to lay focus on conditional generalization\n",
    "df_cubic = df.copy()\n",
    "df_cubic.loc[:, \"weight\"] = 1\n",
    "\n",
    "print(df_cubic.shape)\n",
    "\n",
    "# this is our extra validation timepoint\n",
    "# Note, that for a fair comparison we provide this sample as training data to FSI\n",
    "add_time_cond = (3, 0.15)\n",
    "\n",
    "# Filtering for target validation time and c\n",
    "df_cubic_valid = df_cubic.loc[\n",
    "    ((df_cubic[\"c\"] == 3) & (df_cubic[\"time\"].isin([0, 0.1, 0.15, 0.5, 0.9, 1.0])))\n",
    "    | ((df_cubic[\"c\"] == 5) & (df_cubic[\"time\"].isin([0, 0.15, 0.3, 0.5, 0.7,1.0])))\n",
    "    | ((df_cubic[\"c\"] != 3) & (df_cubic[\"c\"] != 5) & (df_cubic[\"time\"].isin([0, 0.1, 0.15, 0.3, 0.5, 0.7, 0.9, 1.0])))\n",
    "]\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"] == 0.15), \"weight\"] = 10\n",
    "\n",
    "model_battery, model_guidances, model_states = get_model_battery_of_best_models_wc(\n",
    "    df_cubic_valid, select_by, n_top_seeds, model_string, DGP, average_out_seed=True, selector=\"mean\"\n",
    ")\n",
    "\n",
    "X_test, y_test, t_test, n_classes, timepoints, all_classes = dgp_waves_data(\n",
    "    coupling, batch_size, dimension, off_diagonal, data_std, ns_per_t_and_c, dgp=DGP, return_data=\"test\"\n",
    ")\n",
    "\n",
    "x_means = np.concatenate(\n",
    "    [np.zeros(shape=(X_test[:, 0].shape[0], 1)), np.ones(shape=(X_test[:, 0].shape[0], 1))], axis=1\n",
    ")\n",
    "conditions = np.repeat(label_list, 50)\n",
    "x_means[:, 1] = (conditions - 1) / 2\n",
    "x_means += np.random.normal(0, 0.001, x_means.shape)  # Add a bit of noise\n",
    "\n",
    "results_mmfm = Dict()\n",
    "trajectories_test_mmfm = Dict()\n",
    "\n",
    "for seed, model in model_battery.items():\n",
    "    results = []\n",
    "    for idx, c in enumerate(label_list):\n",
    "        trajectories_test_mmfm[c][seed] = sample_trajectory(\n",
    "            model,\n",
    "            X=x_means,\n",
    "            y=y_test[:, 0],\n",
    "            device=device,\n",
    "            guidance=model_guidances[c],\n",
    "            conditional_model=model_states[seed][\"conditional_model\"],\n",
    "            rtol=1e-7,\n",
    "            atol=1e-9,\n",
    "            steps=101,\n",
    "            method=\"rk4\",\n",
    "        )\n",
    "\n",
    "        trajectory = np.swapaxes(trajectories_test_mmfm[c][seed], 0, 1)\n",
    "        trajectory = trajectory[\n",
    "            np.arange(trajectory.shape[0])[:, None], (t_test * (trajectory.shape[1] - 1)).astype(int)\n",
    "        ]\n",
    "\n",
    "        for marginal in range(trajectory.shape[1]):\n",
    "            target = X_test[:, marginal][y_test[:, marginal] == c]\n",
    "            transport = trajectory[:, marginal][y_test[:, 0] == c]\n",
    "            mmd, mmd_median, wasserstein, mean_diff_l1, mean_diff_l2, kl_div = compute_metric_set(target, transport)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"marginal\": marginal,\n",
    "                    \"c\": c,\n",
    "                    \"mmd\": mmd,\n",
    "                    \"mmd_median\": mmd_median,\n",
    "                    \"wasserstein\": wasserstein,\n",
    "                    \"guidance\": model_guidances[c],\n",
    "                    \"train\": False,\n",
    "                    \"time\": t_test[0, marginal],\n",
    "                    \"mean_diff_l1\": mean_diff_l1,\n",
    "                    \"mean_diff_l2\": mean_diff_l2,\n",
    "                    \"kl_div\": kl_div,\n",
    "                    \"seed\": seed,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_mmfm[seed] = pd.DataFrame(results)\n",
    "\n",
    "df_cubic_results_mmfm = pd.concat([results_mmfm[seed] for seed in results_mmfm], axis=0)\n",
    "df_cubic_results_mmfm[\"model\"] = \"COT-MMFM\"\n",
    "\n",
    "for seed in range(3):\n",
    "    try:\n",
    "        plot_models_wc(\n",
    "            trajectories_test_mmfm,\n",
    "            6,\n",
    "            20,\n",
    "            coupling,\n",
    "            batch_size,\n",
    "            dimension,\n",
    "            off_diagonal,\n",
    "            data_std,\n",
    "            ns_per_t_and_c,\n",
    "            DGP,\n",
    "            seed,\n",
    "            save=True,\n",
    "        )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average conditional trajectories for each condition\n",
    "trj = {\n",
    "    c: np.mean([trajectories_test_mmfm[c][seed] for seed in trajectories_test_mmfm[c].keys()], axis=0)\n",
    "    for c in label_list\n",
    "}\n",
    "for c in trj.keys():\n",
    "    trj[c] = {0: trj[c]}\n",
    "\n",
    "plot_models_wc(\n",
    "    trj, 6, 20, coupling, batch_size, dimension, off_diagonal, data_std, ns_per_t_and_c, DGP, 0, save=True, suffix=\"avg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(20, 5), sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "def plot_background(ax, X, y, t, arrows=False, legend=False):\n",
    "    df = pd.DataFrame(X.reshape(-1, 2)).assign(condition=y.reshape(-1, 1), time=t.reshape(-1, 1))\n",
    "    df.columns = [\"x\", \"y\", \"condition\", \"time\"]\n",
    "    df = df.loc[~df[\"condition\"].isna()]\n",
    "    sns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"condition\", ax=ax, s=10, palette=COLORMAP12, legend=legend)\n",
    "    if arrows:\n",
    "        for c in label_list:\n",
    "            t = np.linspace(0, 1, 101)\n",
    "            sol = odeint(u, (0, (c - 1) / 2), t, args=(c,))\n",
    "            ax.plot(sol[:, 0], sol[:, 1], color=\"gray\", alpha=0.5, lw=2)\n",
    "            for idx in [20, 40, 60, 80]:\n",
    "                ax.arrow(\n",
    "                    sol[idx, 0],\n",
    "                    sol[idx, 1],\n",
    "                    sol[idx + 1, 0] - sol[idx, 0],\n",
    "                    sol[idx + 1, 1] - sol[idx, 1],\n",
    "                    color=\"gray\",\n",
    "                    alpha=0.25,\n",
    "                    head_width=0.05,\n",
    "                    head_length=0.05,\n",
    "                    fc=\"black\",\n",
    "                    ec=\"black\",\n",
    "                )\n",
    "    return ax\n",
    "\n",
    "\n",
    "#\n",
    "# Figure 1 is true vector field and measurements\n",
    "#\n",
    "add_time_cond = [(i, 0.15) for i in label_list]\n",
    "train_loader, X_train, y_train, t_train, X_valid, y_valid, t_valid, n_classes, label_list = dgp_waves_data(\n",
    "    coupling,\n",
    "    batch_size,\n",
    "    dimension,\n",
    "    off_diagonal,\n",
    "    data_std,\n",
    "    ns_per_t_and_c,\n",
    "    dgp=DGP,\n",
    "    return_data=\"train-valid\",\n",
    "    add_time_cond=add_time_cond,\n",
    "    filter_beginning_end=False,\n",
    ")\n",
    "ax[0] = plot_background(ax[0], X_train, y_train, t_train, arrows=True)\n",
    "ax[0].set_title(\"True Vector Field (Phase Diagram)\\nwith Training Data\", fontsize=18)\n",
    "\n",
    "\n",
    "#\n",
    "# Figure 2 shows FSI interpolation\n",
    "#\n",
    "add_time_cond = [(i, 0.15) for i in label_list]\n",
    "train_loader, X_train, y_train, t_train, X_valid, y_valid, t_valid, n_classes, label_list = dgp_waves_data(\n",
    "    coupling,\n",
    "    batch_size,\n",
    "    dimension,\n",
    "    off_diagonal,\n",
    "    data_std,\n",
    "    ns_per_t_and_c,\n",
    "    dgp=DGP,\n",
    "    return_data=\"train-valid\",\n",
    "    add_time_cond=add_time_cond,\n",
    "    filter_beginning_end=False,\n",
    ")\n",
    "ax[1] = plot_background(ax[1], X_train, y_train, t_train, arrows=False)\n",
    "ax[1].set_title(\"Predicted Trajectory FSI\", fontsize=18)\n",
    "# Plot interpolation between one sample per condition, use a natural cubic spline\n",
    "for seed in range(1):\n",
    "    filename = f\"dgp_waves_{DGP}_{seed}_{ns_per_t_and_c}_{train_test_split}_{off_diagonal}_{data_std}_{dimension}\"\n",
    "    if add_time_cond:\n",
    "        filename = filename + \"_\" + re.sub(r\"[(), ]\", \"\", str(add_time_cond))\n",
    "    results_path = Path(path_name_fsi) / filename\n",
    "\n",
    "    if coupling == \"ot\":\n",
    "        name = \"model_ot_fsi.pkl\"\n",
    "    elif coupling == \"cot\":\n",
    "        name = \"model_cot_fsi.pkl\"\n",
    "    elif coupling == \"None\":\n",
    "        name = \"model_fsi.pkl\"\n",
    "    else:\n",
    "        raise ValueError(\"Coupling not recognized.\")\n",
    "\n",
    "    with open(results_path / name, \"rb\") as f:\n",
    "        fsi_model = cloudpickle.load(f)\n",
    "\n",
    "    # Plot trajectory\n",
    "    for idx_c, condition in enumerate([2, 3, 5, 6.5]):\n",
    "        color_conditions = list(label_list).index(condition)\n",
    "        T = 100\n",
    "        trajectory = np.nan * np.ones(shape=(T + 1, 10, 2))\n",
    "        for idx, sample in enumerate(range(5)):\n",
    "            sample_c = np.where(y_test[:, 0] == condition)[0]\n",
    "            for tx in range(T + 1):\n",
    "                transport_c = fsi_model.interpolate_from_x0(\n",
    "                    # X=X_test[sample_c[sample], 0][None, :],\n",
    "                    X=x_means[sample_c[sample]][None, :],\n",
    "                    y=condition,\n",
    "                    t_query=tx / T,\n",
    "                )\n",
    "                trajectory[tx, idx] = transport_c\n",
    "\n",
    "        for sample in range(3):\n",
    "            for t in range(T):\n",
    "                ax[1].plot(\n",
    "                    [trajectory[t, sample, 0], trajectory[t + 1, sample, 0]],\n",
    "                    [trajectory[t, sample, 1], trajectory[t + 1, sample, 1]],\n",
    "                    color=COLORMAP12[color_conditions],\n",
    "                    lw=3,\n",
    "                )\n",
    "\n",
    "#\n",
    "# Figure 3 shows MMFM Predicted Trajectory\n",
    "#\n",
    "add_time_cond = None\n",
    "train_loader, X_train, y_train, t_train, X_valid, y_valid, t_valid, n_classes, label_list = dgp_waves_data(\n",
    "    coupling,\n",
    "    batch_size,\n",
    "    dimension,\n",
    "    off_diagonal,\n",
    "    data_std,\n",
    "    ns_per_t_and_c,\n",
    "    dgp=DGP,\n",
    "    return_data=\"train-valid\",\n",
    "    add_time_cond=add_time_cond,\n",
    "    filter_beginning_end=False,\n",
    ")\n",
    "ax[2] = plot_background(ax[2], X_train, y_train, t_train, arrows=False, legend=True)\n",
    "ax[2].set_title(\"Predicted Trajectory COT-MMFM\", fontsize=18)\n",
    "\n",
    "# Plot interpolation between one sample per condition, use a natural cubic spline\n",
    "for seed in range(1):\n",
    "    for idx, condition in enumerate([2, 3, 5, 6.5]):\n",
    "        color_conditions = list(label_list).index(condition)\n",
    "        sub_trajectories = trajectories_test_mmfm[condition][1][\n",
    "            :, ((color_conditions) * 50) : ((color_conditions + 1) * 50)\n",
    "        ]\n",
    "        for sample in range(3):\n",
    "            for t in range(T):\n",
    "                # Connect two coordinates by line\n",
    "                ax[2].plot(\n",
    "                    [sub_trajectories[t, sample, 0], sub_trajectories[t + 1, sample, 0]],\n",
    "                    [sub_trajectories[t, sample, 1], sub_trajectories[t + 1, sample, 1]],\n",
    "                    color=COLORMAP12[color_conditions],\n",
    "                    lw=3,\n",
    "                )\n",
    "\n",
    "# Create a single legend for the figure\n",
    "handles, labels = fig.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(\n",
    "    by_label.values(),\n",
    "    by_label.keys(),\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(0.86, 0.5),\n",
    "    handler_map={plt.Line2D: ThickerLine2D()},\n",
    ")\n",
    "\n",
    "for k in range(3):\n",
    "    ax[k].set_xlabel(\"x\")\n",
    "    ax[k].set_ylabel(\"y\")\n",
    "\n",
    "# Remove legend from third subplot\n",
    "ax[2].get_legend().remove()\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(right=0.85)\n",
    "# Add dots at integer coordinates\n",
    "for a in ax.flatten():\n",
    "    x_dots = np.linspace(-0.1, 3.1, 23)\n",
    "    y_dots = np.linspace(-0.3, 4.3, 24)\n",
    "    for x in x_dots:\n",
    "        for y in y_dots:\n",
    "            a.scatter(x, y, color=\"gray\", s=2, alpha=0.5, marker=\"+\")\n",
    "\n",
    "# Incease x ticks labels and axis labels\n",
    "for a in ax:\n",
    "    a.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "    a.set_xlabel(a.get_xlabel(), fontsize=16)\n",
    "    a.set_ylabel(a.get_ylabel(), fontsize=16)\n",
    "\n",
    "# Save figure as png\n",
    "plt.savefig(\"/home/rohbeckm/code/mmfm/figures_paper/gt_fsi_mmfm_35.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to disk\n",
    "load_results = False\n",
    "save_results = True\n",
    "\n",
    "if load_results:\n",
    "    df_cubic_results_mmfm = pd.read_csv(\"final_df_cubic_results_mmfm.csv\")\n",
    "\n",
    "if save_results:\n",
    "    df_cubic_results_mmfm.to_csv(\"final_df_cubic_results_mmfm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark vs Competitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, t_test, n_classes, timepoints, all_classes = dgp_waves_data(\n",
    "    coupling, batch_size, dimension, off_diagonal, data_std, ns_per_t_and_c, dgp=DGP, return_data=\"test\"\n",
    ")\n",
    "\n",
    "# Evaluate FSI models on the same TEST data\n",
    "df_cubic_results_fsi = []\n",
    "add_time_cond = [(i, 0.15) for i in label_list]  # This is the holdout timepoint, FSI is allowed to use\n",
    "for seed in range(5):\n",
    "    filename = f\"dgp_waves_{DGP}_{seed}_{ns_per_t_and_c}_{train_test_split}_{off_diagonal}_{data_std}_{dimension}\"\n",
    "    if add_time_cond is not None:\n",
    "        filename = filename + \"_\" + re.sub(r\"[(), ]\", \"\", str(add_time_cond))\n",
    "    results_path = Path(path_name_fsi) / filename\n",
    "\n",
    "    df_results_fsi = predict_on_testset_fsi(\n",
    "        results_path,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        t_test,\n",
    "        seed=seed,\n",
    "        coupling=coupling,\n",
    "        n_classes=len(label_list),\n",
    "        plot_results=True if seed == 0 else False,\n",
    "        ncols=6,\n",
    "        plot_ode=\"u\",\n",
    "    )\n",
    "    df_cubic_results_fsi.append(df_results_fsi)\n",
    "\n",
    "df_cubic_results_fsi = pd.concat(df_cubic_results_fsi).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to disk\n",
    "load_results = False\n",
    "save_results = True\n",
    "\n",
    "if load_results:\n",
    "    df_cubic_results_fsi = pd.read_csv(\"final_df_cubic_results_fsi.csv\")\n",
    "\n",
    "if save_results:\n",
    "    df_cubic_results_fsi.to_csv(\"final_df_cubic_results_fsi.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, grouping_columns, performance_columns = load_all_models(\n",
    "    PROD, DGP, load_parquet=True, coupling=coupling, embedding_type=embedding_type, filter_values=\"_fm\"\n",
    ")\n",
    "model_type = \"fm\"\n",
    "\n",
    "print(f\"Data before filtering: {df.shape}\")\n",
    "\n",
    "df = df.loc[\n",
    "    (df[\"ns_per_t_and_c\"] == ns_per_t_and_c)\n",
    "    & (df[\"coupling\"] == coupling)\n",
    "    & (df[\"data_std\"] == data_std)\n",
    "    & (df[\"off_diagonal\"] == off_diagonal)\n",
    "    & (df[\"train_test_split\"] == train_test_split)\n",
    "    & (df[\"model_type\"] == model_type)\n",
    "]\n",
    "if not classifier_free:\n",
    "    df = df.loc[~df[\"classifier_free\"]]\n",
    "\n",
    "# Filter for validation results\n",
    "df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "df = df.loc[~df[\"train\"]]\n",
    "\n",
    "print(f\"Data after 1st filtering: {df.shape}\")\n",
    "\n",
    "df, grouping_columns, performance_columns = process_all_fm_models(\n",
    "    df,\n",
    "    grouping_columns,\n",
    "    performance_columns,\n",
    "    plot=False,\n",
    "    verbose=False,\n",
    "    minimum_seeds=5,\n",
    "    data_cols=[\n",
    "        \"ns_per_t_and_c\",\n",
    "        \"coupling\",\n",
    "        \"data_std\",\n",
    "        \"dgp\",\n",
    "        \"interpolation\",\n",
    "        \"guidance\",\n",
    "        \"embedding_type\",\n",
    "        \"classifier_free\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_cubic = df.loc[(df[\"interpolation\"] == \"cubic\")]\n",
    "\n",
    "print(f\"Data after 2nd filtering: {df_cubic.shape}\")\n",
    "\n",
    "\n",
    "df_cubic = df_cubic.copy()\n",
    "df_cubic.loc[:, \"weight\"] = 1\n",
    "\n",
    "df_cubic_valid = df_cubic.loc[(df_cubic[\"time\"].isin([0, 1.0]))]\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"] == 0.15), \"weight\"] = 10\n",
    "\n",
    "model_battery, model_guidances, model_states = get_model_battery_of_best_models_wc(\n",
    "    df_cubic_valid, select_by, n_top_seeds, model_string, DGP, average_out_seed=True, selector=\"mean\"\n",
    ")\n",
    "\n",
    "X_test, y_test, t_test, n_classes, timepoints, all_classes = dgp_waves_data(\n",
    "    coupling, batch_size, dimension, off_diagonal, data_std, ns_per_t_and_c, dgp=DGP, return_data=\"test\"\n",
    ")\n",
    "\n",
    "results_fm = Dict()\n",
    "trajectories_test_fm = Dict()\n",
    "\n",
    "for seed, model in model_battery.items():\n",
    "    results = []\n",
    "    for idx, c in enumerate(label_list):\n",
    "        trajectories_test_fm[c][seed] = sample_trajectory(\n",
    "            model,\n",
    "            X=x_means,\n",
    "            y=y_test[:, 0],\n",
    "            device=device,\n",
    "            guidance=model_guidances[c],\n",
    "            conditional_model=model_states[seed][\"conditional_model\"],\n",
    "            rtol=1e-7,\n",
    "            atol=1e-9,\n",
    "            steps=101,\n",
    "            method=\"rk4\",\n",
    "        )\n",
    "\n",
    "        trajectory = np.swapaxes(trajectories_test_fm[c][seed], 0, 1)\n",
    "        trajectory = trajectory[\n",
    "            np.arange(trajectory.shape[0])[:, None], (t_test * (trajectory.shape[1] - 1)).astype(int)\n",
    "        ]\n",
    "\n",
    "        for marginal in range(trajectory.shape[1]):\n",
    "            target = X_test[:, marginal][y_test[:, marginal] == c]\n",
    "            transport = trajectory[:, marginal][y_test[:, 0] == c]\n",
    "            mmd, mmd_median, wasserstein, mean_diff_l1, mean_diff_l2, kl_div = compute_metric_set(target, transport)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"marginal\": marginal,\n",
    "                    \"c\": c,\n",
    "                    \"mmd\": mmd,\n",
    "                    \"mmd_median\": mmd_median,\n",
    "                    \"wasserstein\": wasserstein,\n",
    "                    \"guidance\": model_guidances[c],\n",
    "                    \"train\": False,\n",
    "                    \"time\": t_test[0, marginal],\n",
    "                    \"mean_diff_l1\": mean_diff_l1,\n",
    "                    \"mean_diff_l2\": mean_diff_l2,\n",
    "                    \"kl_div\": kl_div,\n",
    "                    \"seed\": seed,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_fm[seed] = pd.DataFrame(results)\n",
    "\n",
    "df_cubic_results_fm = pd.concat([results_fm[seed] for seed in results_fm], axis=0)\n",
    "df_cubic_results_fm[\"model\"] = \"OT-CFM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to disk\n",
    "load_results = False\n",
    "save_results = True\n",
    "\n",
    "if load_results:\n",
    "    df_cubic_results_fm = pd.read_csv(\"final_df_cubic_results_fm.csv\")\n",
    "\n",
    "if save_results:\n",
    "    df_cubic_results_fm.to_csv(\"final_df_cubic_results_fm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear COT-MMFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, grouping_columns, performance_columns = load_all_models(\n",
    "    PROD, DGP, load_parquet=True, coupling=coupling, embedding_type=embedding_type, filter_values=\"_mmfm\"\n",
    ")\n",
    "model_type = \"mmfm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data before filtering: {df.shape}\")\n",
    "\n",
    "df = df.loc[\n",
    "    (df[\"ns_per_t_and_c\"] == ns_per_t_and_c)\n",
    "    & (df[\"coupling\"] == coupling)\n",
    "    & (df[\"data_std\"] == data_std)\n",
    "    & (df[\"off_diagonal\"] == off_diagonal)\n",
    "    & (df[\"train_test_split\"] == train_test_split)\n",
    "    & (df[\"model_type\"] == model_type)\n",
    "]\n",
    "if not classifier_free:\n",
    "    df = df.loc[~df[\"classifier_free\"]]\n",
    "\n",
    "# Filter for validation results\n",
    "df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "df = df.loc[~df[\"train\"]]\n",
    "\n",
    "print(f\"Data after 1st filtering: {df.shape}\")\n",
    "\n",
    "df, grouping_columns, performance_columns = process_all_fm_models(\n",
    "    df,\n",
    "    grouping_columns,\n",
    "    performance_columns,\n",
    "    plot=False,\n",
    "    verbose=False,\n",
    "    minimum_seeds=5,\n",
    "    data_cols=[\n",
    "        \"ns_per_t_and_c\",\n",
    "        \"coupling\",\n",
    "        \"data_std\",\n",
    "        \"dgp\",\n",
    "        \"interpolation\",\n",
    "        \"guidance\",\n",
    "        \"embedding_type\",\n",
    "        \"classifier_free\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_cubic = df.loc[(df[\"interpolation\"] == \"linear\")]\n",
    "\n",
    "print(f\"Data after 2nd filtering: {df_cubic.shape}\")\n",
    "\n",
    "df_cubic = df_cubic.copy()\n",
    "df_cubic.loc[:, \"weight\"] = 1\n",
    "\n",
    "df_cubic_valid = df_cubic.loc[\n",
    "    ((df_cubic[\"c\"] == 3) & (df_cubic[\"time\"].isin([0, 0.1, 0.15, 0.5, 0.9, 1.0])))\n",
    "    | ((df_cubic[\"c\"] == 5) & (df_cubic[\"time\"].isin([0, 0.15, 0.3, 0.5, 0.7, 1.0])))\n",
    "    | ((df_cubic[\"c\"] != 3) & (df_cubic[\"c\"] != 5) & (df_cubic[\"time\"].isin([0, 0.1, 0.15, 0.3, 0.5, 0.7, 0.9, 1.0])))\n",
    "]\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"] == 0.15), \"weight\"] = 10\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"].isin([1])), \"weight\"] = 5\n",
    "\n",
    "model_battery, model_guidances, model_states = get_model_battery_of_best_models_wc(\n",
    "    df_cubic_valid, select_by, n_top_seeds, model_string, DGP, average_out_seed=True, selector=\"mean\"\n",
    ")\n",
    "\n",
    "X_test, y_test, t_test, n_classes, timepoints, all_classes = dgp_waves_data(\n",
    "    coupling, batch_size, dimension, off_diagonal, data_std, ns_per_t_and_c, dgp=DGP, return_data=\"test\"\n",
    ")\n",
    "\n",
    "\n",
    "results_mmfmlin = Dict()\n",
    "trajectories_test_mmfmlin = Dict()\n",
    "\n",
    "for seed, model in model_battery.items():\n",
    "    results = []\n",
    "    for idx, c in enumerate(label_list):\n",
    "        trajectories_test_mmfmlin[c][seed] = sample_trajectory(\n",
    "            model,\n",
    "            X=x_means,\n",
    "            y=y_test[:, 0],\n",
    "            device=device,\n",
    "            guidance=model_guidances[c],\n",
    "            conditional_model=model_states[seed][\"conditional_model\"],\n",
    "            rtol=1e-7,\n",
    "            atol=1e-9,\n",
    "            steps=101,\n",
    "            method=\"rk4\",\n",
    "        )\n",
    "\n",
    "        trajectory = np.swapaxes(trajectories_test_mmfmlin[c][seed], 0, 1)\n",
    "        trajectory = trajectory[\n",
    "            np.arange(trajectory.shape[0])[:, None], (t_test * (trajectory.shape[1] - 1)).astype(int)\n",
    "        ]\n",
    "\n",
    "        for marginal in range(trajectory.shape[1]):\n",
    "            target = X_test[:, marginal][y_test[:, marginal] == c]\n",
    "            transport = trajectory[:, marginal][y_test[:, 0] == c]\n",
    "            mmd, mmd_median, wasserstein, mean_diff_l1, mean_diff_l2, kl_div = compute_metric_set(target, transport)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"marginal\": marginal,\n",
    "                    \"c\": c,\n",
    "                    \"mmd\": mmd,\n",
    "                    \"mmd_median\": mmd_median,\n",
    "                    \"wasserstein\": wasserstein,\n",
    "                    \"guidance\": model_guidances[c],\n",
    "                    \"train\": False,\n",
    "                    \"time\": t_test[0, marginal],\n",
    "                    \"mean_diff_l1\": mean_diff_l1,\n",
    "                    \"mean_diff_l2\": mean_diff_l2,\n",
    "                    \"kl_div\": kl_div,\n",
    "                    \"seed\": seed,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_mmfmlin[seed] = pd.DataFrame(results)\n",
    "\n",
    "df_cubic_results_mmfmlin = pd.concat([results_mmfmlin[seed] for seed in results_mmfmlin], axis=0)\n",
    "df_cubic_results_mmfmlin[\"model\"] = \"L-COT-MMFM\"\n",
    "\n",
    "for seed in range(1):\n",
    "    try:\n",
    "        plot_models_wc(\n",
    "            trajectories_test_mmfmlin,\n",
    "            6,\n",
    "            20,\n",
    "            coupling,\n",
    "            batch_size,\n",
    "            dimension,\n",
    "            off_diagonal,\n",
    "            data_std,\n",
    "            ns_per_t_and_c,\n",
    "            DGP,\n",
    "            seed,\n",
    "            save=True,\n",
    "            suffix=\"L-COT-MMFM\",\n",
    "        )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to disk\n",
    "load_results = False\n",
    "save_results = True\n",
    "\n",
    "if load_results:\n",
    "    df_cubic_results_mmfmlin = pd.read_csv(\"final_df_cubic_results_mmfmlin.csv\")\n",
    "\n",
    "if save_results:\n",
    "    df_cubic_results_mmfmlin.to_csv(\"final_df_cubic_results_mmfmlin.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TC-OT-CFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, grouping_columns, performance_columns = load_all_models(\n",
    "    PROD, DGP, load_parquet=False, coupling=coupling, embedding_type=embedding_type, filter_values=\"_tcotcfm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"tcotcfm\"\n",
    "\n",
    "print(f\"Data before filtering: {df.shape}\")\n",
    "\n",
    "df = df.loc[\n",
    "    (df[\"ns_per_t_and_c\"] == ns_per_t_and_c)\n",
    "    & (df[\"coupling\"] == coupling)\n",
    "    & (df[\"data_std\"] == data_std)\n",
    "    & (df[\"off_diagonal\"] == off_diagonal)\n",
    "    & (df[\"train_test_split\"] == train_test_split)\n",
    "    & (df[\"model_type\"] == model_type)\n",
    "]\n",
    "if not classifier_free:\n",
    "    df = df.loc[~df[\"classifier_free\"]]\n",
    "\n",
    "# Filter for validation results\n",
    "df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "df = df.loc[~df[\"train\"]]\n",
    "\n",
    "print(f\"Data after 1st filtering: {df.shape}\")\n",
    "\n",
    "df, grouping_columns, performance_columns = process_all_fm_models(\n",
    "    df,\n",
    "    grouping_columns,\n",
    "    performance_columns,\n",
    "    plot=False,\n",
    "    verbose=True,\n",
    "    minimum_seeds=5,\n",
    "    data_cols=[\n",
    "        \"ns_per_t_and_c\",\n",
    "        \"coupling\",\n",
    "        \"data_std\",\n",
    "        \"dgp\",\n",
    "        \"interpolation\",\n",
    "        \"guidance\",\n",
    "        \"embedding_type\",\n",
    "        \"classifier_free\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# df_cubic = df.loc[(df[\"interpolation\"] == \"linear\")]\n",
    "\n",
    "print(f\"Data after 2nd filtering: {df.shape}\")\n",
    "\n",
    "df_cubic = df.copy()\n",
    "df_cubic.loc[:, \"weight\"] = 1\n",
    "\n",
    "df_cubic_valid = df_cubic.loc[\n",
    "    ((df_cubic[\"c\"] == 3) & (df_cubic[\"time\"].isin([0, 0.1, 0.15, 0.5, 0.9, 1.0])))\n",
    "    | ((df_cubic[\"c\"] == 5) & (df_cubic[\"time\"].isin([0, 0.15, 0.3, 0.5, 0.7, 1.0])))\n",
    "    | ((df_cubic[\"c\"] != 3) & (df_cubic[\"c\"] != 5) & (df_cubic[\"time\"].isin([0, 0.1, 0.15, 0.3, 0.5, 0.7, 0.9, 1.0])))\n",
    "]\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"] == 0.15), \"weight\"] = 10\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"].isin([1])), \"weight\"] = 5\n",
    "\n",
    "model_battery, model_guidances, model_states = get_model_battery_of_best_models_wc(\n",
    "    df_cubic_valid, select_by, n_top_seeds, model_string, DGP, average_out_seed=True, selector=\"mean\", model=\"tcotcfm\"\n",
    ")\n",
    "\n",
    "X_test, y_test, t_test, n_classes, timepoints, all_classes = dgp_waves_data(\n",
    "    coupling, batch_size, dimension, off_diagonal, data_std, ns_per_t_and_c, dgp=DGP, return_data=\"test\"\n",
    ")\n",
    "\n",
    "results_tcotcfm = Dict()\n",
    "trajectories_test_tcotcfm = Dict()\n",
    "\n",
    "for seed, model in model_battery.items():\n",
    "    results = []\n",
    "    for idx, c in enumerate(label_list):\n",
    "        trajectories_test_tcotcfm[c][seed] = sample_trajectory(\n",
    "            model,\n",
    "            X=x_means[y_test[:, 0] == c, :],\n",
    "            y=y_test[y_test[:, 0] == c, 0],\n",
    "            device=device,\n",
    "            guidance=model_guidances[c],\n",
    "            conditional_model=model_states[seed][\"conditional_model\"],\n",
    "            rtol=1e-7,\n",
    "            atol=1e-9,\n",
    "            steps=101,\n",
    "            method=\"rk4\",\n",
    "        )\n",
    "\n",
    "        trajectory = np.swapaxes(trajectories_test_tcotcfm[c][seed], 0, 1)\n",
    "        trajectory = trajectory[\n",
    "            np.arange(trajectory.shape[0])[:, None],\n",
    "            (t_test[y_test[:, 0] == c, :] * (trajectory.shape[1] - 1)).astype(int),\n",
    "        ]\n",
    "\n",
    "        for marginal in range(trajectory.shape[1]):\n",
    "            target = X_test[:, marginal][y_test[:, marginal] == c]\n",
    "            transport = trajectory[:, marginal]  # [y_test[:, 0] == c]\n",
    "            mmd, mmd_median, wasserstein, mean_diff_l1, mean_diff_l2, kl_div = compute_metric_set(\n",
    "                target, transport, kl_div_skip=True\n",
    "            )\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"marginal\": marginal,\n",
    "                    \"c\": c,\n",
    "                    \"mmd\": mmd,\n",
    "                    \"mmd_median\": mmd_median,\n",
    "                    \"wasserstein\": wasserstein,\n",
    "                    \"guidance\": model_guidances[c],\n",
    "                    \"train\": False,\n",
    "                    \"time\": t_test[0, marginal],\n",
    "                    \"mean_diff_l1\": mean_diff_l1,\n",
    "                    \"mean_diff_l2\": mean_diff_l2,\n",
    "                    \"kl_div\": kl_div,\n",
    "                    \"seed\": seed,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_tcotcfm[seed] = pd.DataFrame(results)\n",
    "\n",
    "df_cubic_results_tcotcfm = pd.concat([results_tcotcfm[seed] for seed in results_tcotcfm], axis=0)\n",
    "df_cubic_results_tcotcfm[\"model\"] = \"TC-OT-CFM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in range(1):\n",
    "    plot_models_wc(\n",
    "        trajectories_test_tcotcfm,\n",
    "        6,\n",
    "        20,\n",
    "        coupling,\n",
    "        batch_size,\n",
    "        dimension,\n",
    "        off_diagonal,\n",
    "        data_std,\n",
    "        ns_per_t_and_c,\n",
    "        DGP,\n",
    "        seed,\n",
    "        save=True,\n",
    "        suffix=\"TC-OT-CFM\",\n",
    "        already_subset=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to disk\n",
    "load_results = False\n",
    "save_results = True\n",
    "\n",
    "if load_results:\n",
    "    df_cubic_results_tcotcfm = pd.read_csv(\"final_df_cubic_results_tcotcfm.csv\")\n",
    "\n",
    "if save_results:\n",
    "    df_cubic_results_tcotcfm.to_csv(\"final_df_cubic_results_tcotcfm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-OT-CFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, grouping_columns, performance_columns = load_all_models(\n",
    "    PROD, DGP, load_parquet=False, coupling=coupling, embedding_type=embedding_type, filter_values=\"totcfm\"\n",
    ")\n",
    "print(f\"Data before filtering: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"totcfm\"\n",
    "\n",
    "df = df.loc[\n",
    "    (df[\"ns_per_t_and_c\"] == ns_per_t_and_c)\n",
    "    & (df[\"coupling\"] == coupling)\n",
    "    & (df[\"data_std\"] == data_std)\n",
    "    & (df[\"off_diagonal\"] == off_diagonal)\n",
    "    & (df[\"train_test_split\"] == train_test_split)\n",
    "    & (df[\"model_type\"] == model_type)\n",
    "]\n",
    "if not classifier_free:\n",
    "    df = df.loc[~df[\"classifier_free\"]]\n",
    "\n",
    "# Filter for validation results\n",
    "df.loc[:, \"train\"] = df[\"train\"].astype(bool)\n",
    "df = df.loc[~df[\"train\"]]\n",
    "\n",
    "print(f\"Data after 1st filtering: {df.shape}\")\n",
    "\n",
    "df, grouping_columns, performance_columns = process_all_fm_models(\n",
    "    df,\n",
    "    grouping_columns,\n",
    "    performance_columns,\n",
    "    plot=False,\n",
    "    verbose=True,\n",
    "    minimum_seeds=5,\n",
    "    data_cols=[\n",
    "        \"ns_per_t_and_c\",\n",
    "        \"coupling\",\n",
    "        \"data_std\",\n",
    "        \"dgp\",\n",
    "        \"interpolation\",\n",
    "        \"guidance\",\n",
    "        \"embedding_type\",\n",
    "        \"classifier_free\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Data after 2nd filtering: {df.shape}\")\n",
    "\n",
    "df_cubic = df.copy()\n",
    "df_cubic.loc[:, \"weight\"] = 1\n",
    "\n",
    "df_cubic_valid = df_cubic.loc[\n",
    "    ((df_cubic[\"c\"] == 3) & (df_cubic[\"time\"].isin([0, 0.1, 0.15, 0.5, 0.9, 1.0])))\n",
    "    | ((df_cubic[\"c\"] == 5) & (df_cubic[\"time\"].isin([0, 0.15, 0.3, 0.5, 0.7, 1.0])))\n",
    "    | ((df_cubic[\"c\"] != 3) & (df_cubic[\"c\"] != 5) & (df_cubic[\"time\"].isin([0, 0.1, 0.15, 0.3, 0.5, 0.7, 0.9, 1.0])))\n",
    "]\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"] == 0.15), \"weight\"] = 10\n",
    "df_cubic_valid.loc[(df_cubic_valid[\"time\"].isin([1])), \"weight\"] = 5\n",
    "\n",
    "model_battery, model_guidances, model_states = get_model_battery_of_best_models_wc(\n",
    "    df_cubic_valid, select_by, n_top_seeds, model_string, DGP, average_out_seed=True, selector=\"mean\", model=\"totcfm\"\n",
    ")\n",
    "\n",
    "X_test, y_test, t_test, n_classes, timepoints, all_classes = dgp_waves_data(\n",
    "    coupling, batch_size, dimension, off_diagonal, data_std, ns_per_t_and_c, dgp=DGP, return_data=\"test\"\n",
    ")\n",
    "\n",
    "results_totcfm = Dict()\n",
    "trajectories_test_totcfm = Dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed, model in model_battery.items():\n",
    "    results = []\n",
    "    for idx, c in enumerate(label_list):\n",
    "        trajectories_test_totcfm[c][seed] = sample_trajectory(\n",
    "            model,\n",
    "            X=x_means[y_test[:, 0] == c, :],\n",
    "            y=y_test[y_test[:, 0] == c, 0],\n",
    "            device=device,\n",
    "            guidance=model_guidances[c],\n",
    "            conditional_model=model_states[seed][\"conditional_model\"],\n",
    "            rtol=1e-7,\n",
    "            atol=1e-9,\n",
    "            steps=101,\n",
    "            method=\"rk4\",\n",
    "        )\n",
    "\n",
    "        trajectory = np.swapaxes(trajectories_test_totcfm[c][seed], 0, 1)\n",
    "        trajectory = trajectory[\n",
    "            np.arange(trajectory.shape[0])[:, None],\n",
    "            (t_test[y_test[:, 0] == c, :] * (trajectory.shape[1] - 1)).astype(int),\n",
    "        ]\n",
    "\n",
    "        for marginal in range(trajectory.shape[1]):\n",
    "            target = X_test[:, marginal][y_test[:, marginal] == c]\n",
    "            transport = trajectory[:, marginal]  # [y_test[:, 0] == c]\n",
    "            mmd, mmd_median, wasserstein, mean_diff_l1, mean_diff_l2, kl_div = compute_metric_set(\n",
    "                target, transport, kl_div_skip=True\n",
    "            )\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"marginal\": marginal,\n",
    "                    \"c\": c,\n",
    "                    \"mmd\": mmd,\n",
    "                    \"mmd_median\": mmd_median,\n",
    "                    \"wasserstein\": wasserstein,\n",
    "                    \"guidance\": model_guidances[c],\n",
    "                    \"train\": False,\n",
    "                    \"time\": t_test[0, marginal],\n",
    "                    \"mean_diff_l1\": mean_diff_l1,\n",
    "                    \"mean_diff_l2\": mean_diff_l2,\n",
    "                    \"kl_div\": kl_div,\n",
    "                    \"seed\": seed,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_totcfm[seed] = pd.DataFrame(results)\n",
    "\n",
    "df_cubic_results_totcfm = pd.concat([results_totcfm[seed] for seed in results_totcfm], axis=0)\n",
    "df_cubic_results_totcfm[\"model\"] = \"T-OT-CFM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in range(1):\n",
    "    plot_models_wc(\n",
    "        trajectories_test_totcfm,\n",
    "        6,\n",
    "        20,\n",
    "        coupling,\n",
    "        batch_size,\n",
    "        dimension,\n",
    "        off_diagonal,\n",
    "        data_std,\n",
    "        ns_per_t_and_c,\n",
    "        DGP,\n",
    "        seed,\n",
    "        save=True,\n",
    "        suffix=\"T-OT-CFM\",\n",
    "        already_subset=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to disk\n",
    "load_results = False\n",
    "save_results = True\n",
    "\n",
    "if load_results:\n",
    "    df_cubic_results_totcfm = pd.read_csv(\"final_df_cubic_results_totcfm.csv\")\n",
    "\n",
    "if save_results:\n",
    "    df_cubic_results_totcfm.to_csv(\"final_df_cubic_results_totcfm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.concat(\n",
    "    [\n",
    "        df_cubic_results_fm,\n",
    "        df_cubic_results_fsi,\n",
    "        df_cubic_results_mmfmlin,\n",
    "        df_cubic_results_mmfm,\n",
    "        df_cubic_results_tcotcfm,\n",
    "        df_cubic_results_totcfm,\n",
    "    ],\n",
    "    ignore_index=True,\n",
    "    axis=0,\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc[:, \"training\"] = False\n",
    "\n",
    "for model_name in [\"COT-MMFM\", \"L-COT-MMFM\", \"T-OT-CFM\", \"L-COT-MMFM\", \"TC-OT-CFM\"]:\n",
    "    df_results.loc[\n",
    "        (df_results[\"c\"] == 3)\n",
    "        & (df_results[\"model\"] == model_name)\n",
    "        & (df_results[\"time\"].isin([0, 0.1, 0.5, 0.9, 1.0])),\n",
    "        \"training\",\n",
    "    ] = True\n",
    "    df_results.loc[\n",
    "        (df_results[\"c\"] == 5)\n",
    "        & (df_results[\"model\"] == model_name)\n",
    "        & (df_results[\"time\"].isin([0, 0.3, 0.5, 0.7, 1.0])),\n",
    "        \"training\",\n",
    "    ] = True\n",
    "    df_results.loc[\n",
    "        (df_results[\"c\"] != 3)\n",
    "        & (df_results[\"c\"] != 5)\n",
    "        & (df_results[\"model\"] == model_name)\n",
    "        & (df_results[\"time\"].isin([0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0])),\n",
    "        \"training\",\n",
    "    ] = True\n",
    "\n",
    "df_results.loc[\n",
    "    (df_results[\"model\"] == \"OT-CFM\") & (df_results[\"time\"].isin([0, 1.0])),\n",
    "    \"training\",\n",
    "] = True\n",
    "\n",
    "df_results.loc[\n",
    "    (df_results[\"c\"] == 3)\n",
    "    & (df_results[\"model\"] == \"COT-FSI\")\n",
    "    & (df_results[\"time\"].isin([0, 0.1, 0.15, 0.5, 0.9, 1.0])),\n",
    "    \"training\",\n",
    "] = True\n",
    "df_results.loc[\n",
    "    (df_results[\"c\"] == 5)\n",
    "    & (df_results[\"model\"] == \"COT-FSI\")\n",
    "    & (df_results[\"time\"].isin([0, 0.15, 0.3, 0.5, 0.7, 1.0])),\n",
    "    \"training\",\n",
    "] = True\n",
    "df_results.loc[\n",
    "    (df_results[\"c\"] != 3)\n",
    "    & (df_results[\"c\"] != 5)\n",
    "    & (df_results[\"model\"] == \"COT-FSI\")\n",
    "    & (df_results[\"time\"].isin([0, 0.1, 0.15, 0.3, 0.5, 0.7, 0.9, 1.0])),\n",
    "    \"training\",\n",
    "] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = (\n",
    "    df_results.groupby([\"model\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"mmd\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mmd_median\": [\"mean\", \"std\", \"max\"],\n",
    "            \"wasserstein\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mean_diff_l1\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mean_diff_l2\": [\"mean\", \"std\", \"max\"],\n",
    "        }\n",
    "    )\n",
    "    .round(2)\n",
    "    .rename(columns={\"model\": \"Model\"})[[\"mean_diff_l2\", \"wasserstein\"]]\n",
    "    .reset_index()\n",
    ")\n",
    "df_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[\"condition_value\"] = df_results[\"c\"].apply(lambda x: \"3\" if x == 3 else (\"5\" if x == 5 else \"R\"))\n",
    "\n",
    "df_r = (\n",
    "    df_results.groupby([\"model\", \"training\", \"condition_value\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"mmd\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mmd_median\": [\"mean\", \"std\", \"max\"],\n",
    "            \"wasserstein\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mean_diff_l1\": [\"mean\", \"std\", \"max\"],\n",
    "            \"mean_diff_l2\": [\"mean\", \"std\", \"max\"],\n",
    "        }\n",
    "    )\n",
    "    .round(2)\n",
    "    .rename(columns={\"model\": \"Model\"})[[\"mean_diff_l1\", \"mean_diff_l2\", \"wasserstein\", \"mmd\", \"mmd_median\"]]\n",
    "    .reset_index()\n",
    ")\n",
    "df_r = df_r.loc[~df_r[\"training\"]]\n",
    "df_r.sort_values([\"condition_value\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
